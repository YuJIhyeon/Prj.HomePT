{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "german-voltage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "educational-badge",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\Humble\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1761: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "session = tf.compat.v1.InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "massive-compromise",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, glob\n",
    "import cv2\n",
    "\n",
    "image_size = 227\n",
    "\n",
    "#groups_folder_path = '../Images/After_AAFT/'\n",
    "groups_folder_path = '../Images/After_image/'\n",
    "\n",
    "X_s = []\n",
    "\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "desperate-suspect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(227, 227, 3)\n"
     ]
    }
   ],
   "source": [
    "for label in ['Bi', 'Tri']:\n",
    "\n",
    "    for feature in ['striping_midAng_bw']:\n",
    "\n",
    "        for top, dir, f in os.walk(groups_folder_path + label + \"/\" + feature + \"/\"):\n",
    "            for filename in f:\n",
    "                img = cv2.imread(groups_folder_path + label + \"/\" + feature + \"/\" + filename)\n",
    "                img = cv2.resize(img, None, fx=image_size / img.shape[0], fy=image_size / img.shape[1])\n",
    "\n",
    "                #if feature == 'striping_bw':\n",
    "                X_s.append(img / 256)\n",
    "\n",
    "                if label == 'Bi':\n",
    "                    y.append(2)\n",
    "                else:\n",
    "                    y.append(3)\n",
    "\n",
    "print(X_s[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "front-announcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X_s)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "generous-jacob",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119\n",
      "85\n"
     ]
    }
   ],
   "source": [
    "# train, test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# validation split\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.1, random_state=10, stratify=y_train)\n",
    "print(len(y))\n",
    "print(len(y_train))\n",
    "AlexNet = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(256, (6, 6), activation='relu', input_shape=X_train[0].shape),\n",
    "        keras.layers.MaxPooling2D( (2, 2) ),\n",
    "        keras.layers.BatchNormalization(),\n",
    "\n",
    "\n",
    "        keras.layers.Conv2D(384, (3, 3), padding='same', activation='relu'),\n",
    "        keras.layers.MaxPooling2D( (2, 2) ),\n",
    "        keras.layers.BatchNormalization(),\n",
    "\n",
    "        keras.layers.Conv2D(384, (3, 3), padding='same', activation='relu'),\n",
    "        keras.layers.MaxPooling2D( (2, 2) ),\n",
    "        keras.layers.BatchNormalization(),\n",
    "\n",
    "        keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu'),\n",
    "        keras.layers.MaxPooling2D( (2, 2) ),\n",
    "        keras.layers.BatchNormalization(),\n",
    "\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(1024, activation='relu'),\n",
    "        keras.layers.Dense(1024, activation='relu'),\n",
    "\n",
    "        keras.layers.Dense(len(y_train), activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "canadian-burden",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 222, 222, 256)     27904     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 111, 111, 256)     0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 111, 111, 256)     1024      \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 111, 111, 384)     885120    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 55, 55, 384)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 55, 55, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 55, 55, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 27, 27, 384)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 27, 27, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 27, 27, 256)       884992    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 13, 13, 256)       1024      \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 43264)             0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1024)              44303360  \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 85)                87125     \n",
      "=================================================================\n",
      "Total params: 48,570,709\n",
      "Trainable params: 48,568,149\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "AlexNet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "signal-torture",
   "metadata": {},
   "outputs": [],
   "source": [
    "AlexNet.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=0.01),\n",
    "              metrics=[keras.metrics.sparse_categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "integrated-attempt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 153ms/step - loss: 2.1550 - sparse_categorical_accuracy: 0.6200 - val_loss: 4.0893 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 1s 126ms/step - loss: 9.8529e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.9949 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 1s 127ms/step - loss: 4.2531e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.8784 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 1s 127ms/step - loss: 4.1024e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.7920 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 1s 131ms/step - loss: 2.9856e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.7170 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 1s 130ms/step - loss: 2.9713e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.6448 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 1s 126ms/step - loss: 2.1693e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5716 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 1s 127ms/step - loss: 1.9988e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.5001 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 1s 131ms/step - loss: 2.2350e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.4290 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 1s 132ms/step - loss: 1.4998e-04 - sparse_categorical_accuracy: 1.0000 - val_loss: 3.3577 - val_sparse_categorical_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "AlexNet_history = AlexNet.fit(X_train, y_train, epochs=10, batch_size=16,\n",
    "                    validation_data=(X_validation, y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "every-serve",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#print(AlexNet_history.history)\n",
    "\n",
    "plt.plot(AlexNet_history.history['val_sparse_categorical_accuracy'])\n",
    "plt.legend(['val_acc'], loc= 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "visible-expert",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 39ms/step - loss: 3.3584 - sparse_categorical_accuracy: 0.8824\n"
     ]
    }
   ],
   "source": [
    "loss_and_metric = AlexNet.evaluate(X_train, y_train, batch_size = 16, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "celtic-whole",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, loss and metric: [3.358423948287964, 0.8823529481887817]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train, loss and metric: {loss_and_metric}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "formed-regulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 40ms/step - loss: 3.3556 - sparse_categorical_accuracy: 0.9167\n"
     ]
    }
   ],
   "source": [
    "loss_and_metric = AlexNet.evaluate(X_test, y_test, batch_size = 16, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "chronic-detail",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test, loss and metric: [3.3555614948272705, 0.9166666865348816]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test, loss and metric: {loss_and_metric}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Humble",
   "language": "python",
   "name": "humble"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "breeding-flood",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Activation, Input, concatenate, Dropout, Dense, Flatten\n",
    "from keras.layers import MaxPooling2D, Conv2D, AveragePooling2D, BatchNormalization\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.InteractiveSession(config=config)\n",
    "\n",
    "def block_stem(inputs):\n",
    "    net = conv2d(inputs, 32, (3, 3), strides=(2, 2), padding='valid')\n",
    "    net = conv2d(net, 32, (3, 3), padding='valid')\n",
    "    net = conv2d(net, 64, (3, 3))\n",
    "\n",
    "    branch_1 = MaxPooling2D((3, 3), strides=(2, 2), padding='valid')(net)\n",
    "    branch_2 = conv2d(net, 96, (3, 3), strides=(2, 2), padding='valid')\n",
    "\n",
    "    net = concatenate([branch_1, branch_2])\n",
    "\n",
    "    branch_1 = conv2d(net, 64, (1, 1))\n",
    "    branch_1 = conv2d(branch_1, 96, (3, 3), padding='valid')\n",
    "\n",
    "    branch_2 = conv2d(net, 64, (1, 1))\n",
    "    branch_2 = conv2d(branch_2, 64, (7, 1))\n",
    "    branch_2 = conv2d(branch_2, 64, (1, 7))\n",
    "    branch_2 = conv2d(branch_2, 96, (3, 3), padding='valid')\n",
    "\n",
    "    net = concatenate([branch_1, branch_2])\n",
    "\n",
    "    branch_1 = conv2d(net, 192, (3, 3), strides=(2, 2), padding='valid')  # different from the paper\n",
    "    branch_2 = MaxPooling2D((3, 3), strides=(2, 2), padding='valid')(net)\n",
    "\n",
    "    net = concatenate([branch_1, branch_2])\n",
    "\n",
    "    return net\n",
    "\n",
    "\n",
    "def block_inception_a(inputs):\n",
    "    branch_1 = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(inputs)\n",
    "    branch_1 = conv2d(branch_1, 96, (1, 1))\n",
    "\n",
    "    branch_2 = conv2d(inputs, 96, (1, 1))\n",
    "\n",
    "    branch_3 = conv2d(inputs, 64, (1, 1))\n",
    "    branch_3 = conv2d(branch_3, 96, (3, 3))\n",
    "\n",
    "    branch_4 = conv2d(inputs, 64, (1, 1))\n",
    "    branch_4 = conv2d(branch_4, 96, (3, 3))\n",
    "    branch_4 = conv2d(branch_4, 96, (3, 3))\n",
    "\n",
    "    return concatenate([branch_1, branch_2, branch_3, branch_4])\n",
    "\n",
    "\n",
    "def block_inception_b(inputs):\n",
    "    branch_1 = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(inputs)\n",
    "    branch_1 = conv2d(branch_1, 128, (1, 1))\n",
    "\n",
    "    branch_2 = conv2d(inputs, 384, (1, 1))\n",
    "\n",
    "    branch_3 = conv2d(inputs, 192, (1, 1))\n",
    "    branch_3 = conv2d(branch_3, 224, (1, 7))\n",
    "    branch_3 = conv2d(branch_3, 256, (7, 1))  # different from the paper\n",
    "\n",
    "    branch_4 = conv2d(inputs, 192, (1, 1))\n",
    "    branch_4 = conv2d(branch_4, 192, (1, 7))\n",
    "    branch_4 = conv2d(branch_4, 224, (7, 1))\n",
    "    branch_4 = conv2d(branch_4, 224, (1, 7))\n",
    "    branch_4 = conv2d(branch_4, 256, (7, 1))\n",
    "\n",
    "    return concatenate([branch_1, branch_2, branch_3, branch_4])\n",
    "\n",
    "\n",
    "def block_inception_c(inputs):\n",
    "    branch_1 = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(inputs)\n",
    "    branch_1 = conv2d(branch_1, 256, (1, 1))\n",
    "\n",
    "    branch_2 = conv2d(inputs, 256, (1, 1))\n",
    "\n",
    "    branch_3 = conv2d(inputs, 384, (1, 1))\n",
    "    branch_3_1 = conv2d(branch_3, 256, (1, 3))\n",
    "    branch_3_2 = conv2d(branch_3, 256, (3, 1))\n",
    "\n",
    "    branch_4 = conv2d(inputs, 384, (1, 1))\n",
    "    branch_4 = conv2d(branch_4, 448, (1, 3))\n",
    "    branch_4 = conv2d(branch_4, 512, (3, 1))\n",
    "    branch_4_1 = conv2d(branch_4, 256, (3, 1))\n",
    "    branch_4_2 = conv2d(branch_4, 256, (1, 3))\n",
    "\n",
    "    return concatenate([branch_1, branch_2, branch_3_1, branch_3_2, branch_4_1, branch_4_2])\n",
    "\n",
    "\n",
    "def block_reduction_a(inputs):\n",
    "    branch_1 = MaxPooling2D((3, 3), strides=(2, 2), padding='valid')(inputs)\n",
    "\n",
    "    branch_2 = conv2d(inputs, 384, (3, 3), strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch_3 = conv2d(inputs, 192, (1, 1))\n",
    "    branch_3 = conv2d(branch_3, 224, (3, 3))\n",
    "    branch_3 = conv2d(branch_3, 256, (3, 3), strides=(2, 2), padding='valid')\n",
    "\n",
    "    return concatenate([branch_1, branch_2, branch_3])\n",
    "\n",
    "\n",
    "def block_reduction_b(inputs):\n",
    "    branch_1 = MaxPooling2D((3, 3), strides=(2, 2), padding='valid')(inputs)\n",
    "\n",
    "    branch_2 = conv2d(inputs, 192, (1, 1))\n",
    "    branch_2 = conv2d(branch_2, 192, (3, 3), strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch_3 = conv2d(inputs, 256, (1, 1))\n",
    "    branch_3 = conv2d(branch_3, 256, (1, 7))\n",
    "    branch_3 = conv2d(branch_3, 320, (7, 1))\n",
    "    branch_3 = conv2d(branch_3, 320, (3, 3), strides=(2, 2), padding='valid')\n",
    "\n",
    "    return concatenate([branch_1, branch_2, branch_3])\n",
    "\n",
    "\n",
    "def conv2d(net, filters, kernel_size, strides=(1, 1), padding='same'):\n",
    "    net = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding=padding, use_bias=False)(net)\n",
    "    net = BatchNormalization()(net)\n",
    "    net = Activation('relu')(net)\n",
    "    return net\n",
    "\n",
    "def create(classes_num=4):\n",
    "    inputs = Input((227, 227, 3))\n",
    "\n",
    "    # 227 x 227 x 3\n",
    "    net = block_stem(inputs)\n",
    "\n",
    "    # 4 x Inception-A ( Output: 35 x 35 x 384 )\n",
    "    for i in range(4):\n",
    "        net = block_inception_a(net)\n",
    "\n",
    "    # Reduction-A ( Output: 17 x 17 x 1024 )\n",
    "    net = block_reduction_a(net)\n",
    "\n",
    "    # 7 x Inception-B ( Output: 17 x 17 x 1024 )\n",
    "    for i in range(7):\n",
    "        net = block_inception_b(net)\n",
    "\n",
    "    # Reduction-B ( Output: 8 x 8 x 1536 )\n",
    "    net = block_reduction_b(net)\n",
    "\n",
    "    # 3 x Inception-C ( Output: 8 x 8 x 1536 )\n",
    "    for i in range(3):\n",
    "        net = block_inception_c(net)\n",
    "\n",
    "    # Average Pooling ( Output: 1536 )\n",
    "    net = AveragePooling2D((5, 5))(net)\n",
    "\n",
    "    # Dropout ( keep 0.8 )\n",
    "    net = Dropout(0.2)(net)\n",
    "    net = Flatten()(net)\n",
    "\n",
    "    # Output\n",
    "    outputs = Dense(units=classes_num, activation='softmax')(net)\n",
    "\n",
    "    return Model(inputs, outputs, name='Inception-v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "possible-immigration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inceptionV4_model(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    # validation split\n",
    "\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.1, random_state=10,\n",
    "                                                                    stratify=y_train)\n",
    "    print(len(X_train))\n",
    "\n",
    "\n",
    "    model = create()\n",
    "    model.compile(loss=keras.losses.sparse_categorical_crossentropy, metrics=['accuracy'],\n",
    "                  optimizer=keras.optimizers.SGD(learning_rate=0.01))\n",
    "    model.fit(X_train, y_train, batch_size=16, epochs=10, validation_data=(X_validation, y_validation))\n",
    "    \n",
    "    evaluation = []\n",
    "    evaluation.append(model.evaluate(X_train, y_train, batch_size=16))\n",
    "    evaluation.append(model.evaluate(X_test, y_test, batch_size=16))\n",
    "    \n",
    "    return evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "threaded-turkey",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(227, 227, 3)\n",
      "2400\n",
      "1728\n",
      "Epoch 1/10\n",
      "108/108 [==============================] - 47s 217ms/step - loss: 1.2682 - accuracy: 0.4528 - val_loss: 4.5214 - val_accuracy: 0.2500\n",
      "Epoch 2/10\n",
      "108/108 [==============================] - 22s 207ms/step - loss: 0.7866 - accuracy: 0.6828 - val_loss: 1.6260 - val_accuracy: 0.3802\n",
      "Epoch 3/10\n",
      "108/108 [==============================] - 23s 212ms/step - loss: 0.6235 - accuracy: 0.7413 - val_loss: 0.7468 - val_accuracy: 0.6354\n",
      "Epoch 4/10\n",
      "108/108 [==============================] - 22s 204ms/step - loss: 0.5286 - accuracy: 0.7860 - val_loss: 0.3660 - val_accuracy: 0.8594\n",
      "Epoch 5/10\n",
      "108/108 [==============================] - 23s 208ms/step - loss: 0.4064 - accuracy: 0.8542 - val_loss: 0.4029 - val_accuracy: 0.8542\n",
      "Epoch 6/10\n",
      "108/108 [==============================] - 23s 210ms/step - loss: 0.3804 - accuracy: 0.8694 - val_loss: 0.1882 - val_accuracy: 0.9479\n",
      "Epoch 7/10\n",
      "108/108 [==============================] - 23s 210ms/step - loss: 0.3304 - accuracy: 0.8768 - val_loss: 0.2254 - val_accuracy: 0.9167\n",
      "Epoch 8/10\n",
      "108/108 [==============================] - 22s 206ms/step - loss: 0.2828 - accuracy: 0.8910 - val_loss: 0.2747 - val_accuracy: 0.9115\n",
      "Epoch 9/10\n",
      "108/108 [==============================] - 22s 205ms/step - loss: 0.2391 - accuracy: 0.9192 - val_loss: 0.2102 - val_accuracy: 0.9167\n",
      "Epoch 10/10\n",
      "108/108 [==============================] - 22s 205ms/step - loss: 0.2718 - accuracy: 0.9182 - val_loss: 1.4249 - val_accuracy: 0.7656\n",
      "108/108 [==============================] - 7s 62ms/step - loss: 1.2402 - accuracy: 0.7703\n",
      "30/30 [==============================] - 2s 61ms/step - loss: 1.2275 - accuracy: 0.7729\n",
      "1728\n",
      "Epoch 1/10\n",
      "108/108 [==============================] - 30s 217ms/step - loss: 1.2783 - accuracy: 0.4091 - val_loss: 26.0039 - val_accuracy: 0.2500\n",
      "Epoch 2/10\n",
      "108/108 [==============================] - 22s 204ms/step - loss: 0.8848 - accuracy: 0.5698 - val_loss: 10.3834 - val_accuracy: 0.3229\n",
      "Epoch 3/10\n",
      "108/108 [==============================] - 22s 204ms/step - loss: 0.8055 - accuracy: 0.6488 - val_loss: 1.7270 - val_accuracy: 0.4844\n",
      "Epoch 4/10\n",
      "108/108 [==============================] - 22s 204ms/step - loss: 0.5292 - accuracy: 0.7938 - val_loss: 0.5746 - val_accuracy: 0.7500\n",
      "Epoch 5/10\n",
      "108/108 [==============================] - 22s 203ms/step - loss: 0.4397 - accuracy: 0.8333 - val_loss: 0.2548 - val_accuracy: 0.9062\n",
      "Epoch 6/10\n",
      "108/108 [==============================] - 22s 204ms/step - loss: 0.3597 - accuracy: 0.8640 - val_loss: 0.2671 - val_accuracy: 0.8802\n",
      "Epoch 7/10\n",
      "108/108 [==============================] - 22s 203ms/step - loss: 0.2727 - accuracy: 0.8979 - val_loss: 0.4643 - val_accuracy: 0.8594\n",
      "Epoch 8/10\n",
      "108/108 [==============================] - 22s 205ms/step - loss: 0.2570 - accuracy: 0.9083 - val_loss: 0.1679 - val_accuracy: 0.9583\n",
      "Epoch 9/10\n",
      "108/108 [==============================] - 22s 204ms/step - loss: 0.2098 - accuracy: 0.9253 - val_loss: 0.5316 - val_accuracy: 0.8438\n",
      "Epoch 10/10\n",
      "108/108 [==============================] - 22s 203ms/step - loss: 0.2613 - accuracy: 0.9039 - val_loss: 0.1371 - val_accuracy: 0.9479\n",
      "108/108 [==============================] - 6s 60ms/step - loss: 0.0796 - accuracy: 0.9774\n",
      "30/30 [==============================] - 2s 59ms/step - loss: 0.2708 - accuracy: 0.9042\n",
      "1728\n",
      "Epoch 1/10\n",
      "108/108 [==============================] - 29s 214ms/step - loss: 1.2232 - accuracy: 0.4510 - val_loss: 55.7741 - val_accuracy: 0.2500\n",
      "Epoch 2/10\n",
      "108/108 [==============================] - 22s 202ms/step - loss: 0.7871 - accuracy: 0.6384 - val_loss: 14.5613 - val_accuracy: 0.4896\n",
      "Epoch 3/10\n",
      "108/108 [==============================] - 22s 202ms/step - loss: 0.6458 - accuracy: 0.7176 - val_loss: 0.8883 - val_accuracy: 0.6979\n",
      "Epoch 4/10\n",
      "108/108 [==============================] - 22s 203ms/step - loss: 0.5817 - accuracy: 0.7756 - val_loss: 1.1209 - val_accuracy: 0.7708\n",
      "Epoch 5/10\n",
      "108/108 [==============================] - 22s 202ms/step - loss: 0.4846 - accuracy: 0.8274 - val_loss: 0.3861 - val_accuracy: 0.8385\n",
      "Epoch 6/10\n",
      "108/108 [==============================] - 22s 202ms/step - loss: 0.3653 - accuracy: 0.8605 - val_loss: 0.2847 - val_accuracy: 0.9323\n",
      "Epoch 7/10\n",
      "108/108 [==============================] - 22s 203ms/step - loss: 0.3525 - accuracy: 0.8701 - val_loss: 0.2612 - val_accuracy: 0.9219\n",
      "Epoch 8/10\n",
      "108/108 [==============================] - 22s 202ms/step - loss: 0.3204 - accuracy: 0.8859 - val_loss: 0.4061 - val_accuracy: 0.8854\n",
      "Epoch 9/10\n",
      "108/108 [==============================] - 22s 202ms/step - loss: 0.3112 - accuracy: 0.8935 - val_loss: 0.3433 - val_accuracy: 0.8958\n",
      "Epoch 10/10\n",
      "108/108 [==============================] - 22s 202ms/step - loss: 0.2804 - accuracy: 0.8970 - val_loss: 0.1639 - val_accuracy: 0.9427\n",
      "108/108 [==============================] - 6s 59ms/step - loss: 0.1366 - accuracy: 0.9525\n",
      "30/30 [==============================] - 2s 59ms/step - loss: 0.2942 - accuracy: 0.9000\n",
      "1728\n",
      "Epoch 1/10\n",
      "108/108 [==============================] - 29s 214ms/step - loss: 1.2850 - accuracy: 0.4240 - val_loss: 57.3044 - val_accuracy: 0.2500\n",
      "Epoch 2/10\n",
      "108/108 [==============================] - 22s 203ms/step - loss: 0.8401 - accuracy: 0.6160 - val_loss: 12.8621 - val_accuracy: 0.2552\n",
      "Epoch 3/10\n",
      "108/108 [==============================] - 22s 202ms/step - loss: 0.7109 - accuracy: 0.6997 - val_loss: 1.9861 - val_accuracy: 0.6198\n",
      "Epoch 4/10\n",
      "108/108 [==============================] - 22s 202ms/step - loss: 0.5285 - accuracy: 0.7840 - val_loss: 1.0080 - val_accuracy: 0.7188\n",
      "Epoch 5/10\n",
      "108/108 [==============================] - 22s 203ms/step - loss: 0.4555 - accuracy: 0.8214 - val_loss: 2.0240 - val_accuracy: 0.7760\n",
      "Epoch 6/10\n",
      "108/108 [==============================] - 22s 202ms/step - loss: 0.3243 - accuracy: 0.8817 - val_loss: 0.3399 - val_accuracy: 0.8542\n",
      "Epoch 7/10\n",
      "108/108 [==============================] - 22s 201ms/step - loss: 0.2925 - accuracy: 0.8905 - val_loss: 0.3968 - val_accuracy: 0.8333\n",
      "Epoch 8/10\n",
      "108/108 [==============================] - 22s 202ms/step - loss: 0.2820 - accuracy: 0.8949 - val_loss: 0.2375 - val_accuracy: 0.8802\n",
      "Epoch 9/10\n",
      "108/108 [==============================] - 22s 200ms/step - loss: 0.2282 - accuracy: 0.9216 - val_loss: 0.1993 - val_accuracy: 0.9375\n",
      "Epoch 10/10\n",
      "108/108 [==============================] - 22s 200ms/step - loss: 0.1947 - accuracy: 0.9347 - val_loss: 0.2357 - val_accuracy: 0.8958\n",
      "108/108 [==============================] - 6s 59ms/step - loss: 0.1673 - accuracy: 0.9346\n",
      "30/30 [==============================] - 2s 58ms/step - loss: 0.3956 - accuracy: 0.8625\n",
      "1728\n",
      "Epoch 1/10\n",
      "108/108 [==============================] - 29s 212ms/step - loss: 1.2764 - accuracy: 0.4280 - val_loss: 61.5659 - val_accuracy: 0.3125\n",
      "Epoch 2/10\n",
      "108/108 [==============================] - 22s 201ms/step - loss: 0.8655 - accuracy: 0.6006 - val_loss: 13.3829 - val_accuracy: 0.3073\n",
      "Epoch 3/10\n",
      "108/108 [==============================] - 22s 201ms/step - loss: 0.6883 - accuracy: 0.7225 - val_loss: 1.7192 - val_accuracy: 0.5052\n",
      "Epoch 4/10\n",
      "108/108 [==============================] - 22s 200ms/step - loss: 0.5180 - accuracy: 0.8066 - val_loss: 0.9983 - val_accuracy: 0.7917\n",
      "Epoch 5/10\n",
      "108/108 [==============================] - 22s 201ms/step - loss: 0.4034 - accuracy: 0.8467 - val_loss: 0.2586 - val_accuracy: 0.9167\n",
      "Epoch 6/10\n",
      "108/108 [==============================] - 22s 201ms/step - loss: 0.2986 - accuracy: 0.8900 - val_loss: 0.3565 - val_accuracy: 0.8698\n",
      "Epoch 7/10\n",
      "108/108 [==============================] - 22s 201ms/step - loss: 0.2934 - accuracy: 0.9034 - val_loss: 0.2379 - val_accuracy: 0.9062\n",
      "Epoch 8/10\n",
      "108/108 [==============================] - 22s 200ms/step - loss: 0.2286 - accuracy: 0.9114 - val_loss: 0.3309 - val_accuracy: 0.8802\n",
      "Epoch 9/10\n",
      "108/108 [==============================] - 22s 201ms/step - loss: 0.1990 - accuracy: 0.9252 - val_loss: 0.1774 - val_accuracy: 0.9479\n",
      "Epoch 10/10\n",
      "108/108 [==============================] - 22s 200ms/step - loss: 0.1890 - accuracy: 0.9358 - val_loss: 0.1935 - val_accuracy: 0.9323\n",
      "108/108 [==============================] - 6s 58ms/step - loss: 0.0780 - accuracy: 0.9757\n",
      "30/30 [==============================] - 2s 58ms/step - loss: 0.2628 - accuracy: 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728\n",
      "Epoch 1/10\n",
      "108/108 [==============================] - 29s 212ms/step - loss: 1.3099 - accuracy: 0.4007 - val_loss: 286.1374 - val_accuracy: 0.2500\n",
      "Epoch 2/10\n",
      "108/108 [==============================] - 22s 200ms/step - loss: 0.7825 - accuracy: 0.6794 - val_loss: 111.6283 - val_accuracy: 0.2500\n",
      "Epoch 3/10\n",
      "108/108 [==============================] - 22s 201ms/step - loss: 0.6122 - accuracy: 0.7619 - val_loss: 6.6234 - val_accuracy: 0.5260\n",
      "Epoch 4/10\n",
      "108/108 [==============================] - 22s 201ms/step - loss: 0.4781 - accuracy: 0.8229 - val_loss: 0.9197 - val_accuracy: 0.6042\n",
      "Epoch 5/10\n",
      "108/108 [==============================] - 22s 201ms/step - loss: 0.3984 - accuracy: 0.8495 - val_loss: 0.3902 - val_accuracy: 0.8177\n",
      "Epoch 6/10\n",
      "108/108 [==============================] - 22s 201ms/step - loss: 0.2987 - accuracy: 0.8940 - val_loss: 0.2067 - val_accuracy: 0.9167\n",
      "Epoch 7/10\n",
      "108/108 [==============================] - 22s 200ms/step - loss: 0.2544 - accuracy: 0.9043 - val_loss: 0.1751 - val_accuracy: 0.9323\n",
      "Epoch 8/10\n",
      "108/108 [==============================] - 22s 201ms/step - loss: 0.2164 - accuracy: 0.9139 - val_loss: 0.2210 - val_accuracy: 0.9115\n",
      "Epoch 9/10\n",
      "108/108 [==============================] - 22s 201ms/step - loss: 0.1615 - accuracy: 0.9476 - val_loss: 0.1253 - val_accuracy: 0.9427\n",
      "Epoch 10/10\n",
      "108/108 [==============================] - 22s 201ms/step - loss: 0.2256 - accuracy: 0.9214 - val_loss: 0.1025 - val_accuracy: 0.9688\n",
      "108/108 [==============================] - 6s 59ms/step - loss: 0.0589 - accuracy: 0.9861\n",
      "30/30 [==============================] - 2s 59ms/step - loss: 0.2319 - accuracy: 0.9146\n",
      "1728\n",
      "Epoch 1/10\n",
      "108/108 [==============================] - 29s 213ms/step - loss: 1.1948 - accuracy: 0.4867 - val_loss: 315.4138 - val_accuracy: 0.2500\n",
      "Epoch 2/10\n",
      "108/108 [==============================] - 22s 200ms/step - loss: 0.8462 - accuracy: 0.6522 - val_loss: 38.8807 - val_accuracy: 0.2500\n",
      "Epoch 3/10\n",
      "108/108 [==============================] - 22s 200ms/step - loss: 0.6725 - accuracy: 0.7316 - val_loss: 3.4253 - val_accuracy: 0.6094\n",
      "Epoch 4/10\n",
      "108/108 [==============================] - 22s 201ms/step - loss: 0.5363 - accuracy: 0.7819 - val_loss: 0.3690 - val_accuracy: 0.8646\n",
      "Epoch 5/10\n",
      "108/108 [==============================] - 22s 201ms/step - loss: 0.5070 - accuracy: 0.8281 - val_loss: 0.3927 - val_accuracy: 0.8646\n",
      "Epoch 6/10\n",
      "108/108 [==============================] - 22s 201ms/step - loss: 0.3855 - accuracy: 0.8667 - val_loss: 0.9865 - val_accuracy: 0.8073\n",
      "Epoch 7/10\n",
      "108/108 [==============================] - 22s 201ms/step - loss: 0.3299 - accuracy: 0.8859 - val_loss: 0.3752 - val_accuracy: 0.9062\n",
      "Epoch 8/10\n",
      "108/108 [==============================] - 22s 200ms/step - loss: 0.2773 - accuracy: 0.9053 - val_loss: 0.8441 - val_accuracy: 0.8333\n",
      "Epoch 9/10\n",
      "108/108 [==============================] - 22s 201ms/step - loss: 0.2952 - accuracy: 0.8955 - val_loss: 0.3344 - val_accuracy: 0.8906\n",
      "Epoch 10/10\n",
      "108/108 [==============================] - 22s 201ms/step - loss: 0.2118 - accuracy: 0.9208 - val_loss: 0.1751 - val_accuracy: 0.9375\n",
      "108/108 [==============================] - 6s 58ms/step - loss: 0.1405 - accuracy: 0.9508\n",
      "30/30 [==============================] - 2s 58ms/step - loss: 0.3344 - accuracy: 0.8854\n"
     ]
    }
   ],
   "source": [
    "image_size = 227\n",
    "\n",
    "groups_folder_path = '../Data/resultVecsFigs/AAFT_0/'\n",
    "\n",
    "X_s = []\n",
    "\n",
    "y = []\n",
    "# auto_corr   hadamard     midAng    striping_color   striping_bw     striping_midAng_color     striping_midAng_bw\n",
    "for label in ['Bi', 'Tri', 'Hammer', 'Rvcurl']:\n",
    "\n",
    "    for feature in ['hadamard']:\n",
    "\n",
    "        for top, dir, f in os.walk(groups_folder_path + label + \"/\" + feature + \"/\"):\n",
    "            # print(f)\n",
    "            for filename in f:\n",
    "                # print(groups_folder_path + label + \"/\" + feature + \"/\" + filename)\n",
    "                img = cv2.imread(groups_folder_path + label + \"/\" + feature + \"/\" + filename)\n",
    "                img = cv2.resize(img, None, fx=image_size / img.shape[0], fy=image_size / img.shape[1])\n",
    "\n",
    "                X_s.append(img / 256)\n",
    "\n",
    "                if label == 'Bi':\n",
    "                    y.append(0)\n",
    "                elif label =='Tri':\n",
    "                    y.append(1)\n",
    "                elif label == 'Hammer':\n",
    "                    y.append(2)\n",
    "                else:\n",
    "                    y.append(3)\n",
    "\n",
    "print(X_s[0].shape)\n",
    "# print(X_s)\n",
    "print(len(y))\n",
    "X = np.array(X_s)\n",
    "y = np.array(y)\n",
    "\n",
    "ins = []\n",
    "for i in range(10):\n",
    "    ins.append(inceptionV4_model(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "warming-computer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2402151823043823\n",
      "0.0795883983373642\n",
      "0.13663122057914734\n",
      "0.1673271209001541\n",
      "0.07803011685609818\n",
      "0.058898136019706726\n",
      "0.14053960144519806\n"
     ]
    }
   ],
   "source": [
    "for data in ins:\n",
    "    print(data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hispanic-paraguay",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7729166746139526\n",
      "0.9041666388511658\n",
      "0.8999999761581421\n",
      "0.862500011920929\n",
      "0.8999999761581421\n",
      "0.9145833253860474\n",
      "0.8854166865348816\n"
     ]
    }
   ],
   "source": [
    "for data in ins:\n",
    "    print(data[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "appreciated-latitude",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ngroups_folder_path = \\'../Data/resultVecsFigs/AAFT_4/\\'\\nX_s = []\\ny = []\\n# auto_corr   hadamard     midAng    striping_color   striping_bw     striping_midAng_color     striping_midAng_bw\\nfor label in [\\'Bi\\', \\'Tri\\']:\\n\\n    for feature in [\\'hadamard\\']:\\n\\n        for top, dir, f in os.walk(groups_folder_path + label + \"/\" + feature + \"/\"):\\n            # print(f)\\n            for filename in f:\\n                # print(groups_folder_path + label + \"/\" + feature + \"/\" + filename)\\n                img = cv2.imread(groups_folder_path + label + \"/\" + feature + \"/\" + filename)\\n                img = cv2.resize(img, None, fx=image_size / img.shape[0], fy=image_size / img.shape[1])\\n\\n                X_s.append(img / 256)\\n\\n                if label == \\'Bi\\':\\n                    y.append(0)\\n                else:\\n                    y.append(1)\\n\\nprint(X_s[0].shape)\\n# print(X_s)\\nprint(len(y))\\nX = np.array(X_s)\\ny = np.array(y)\\n\\nins = []\\nfor i in range(10):\\n    ins.append(inceptionV4_model(X, y))\\n\\nfor data in ins:\\n    for d in data:\\n        for j in d:\\n            print(j)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "groups_folder_path = '../Data/resultVecsFigs/AAFT_4/'\n",
    "X_s = []\n",
    "y = []\n",
    "# auto_corr   hadamard     midAng    striping_color   striping_bw     striping_midAng_color     striping_midAng_bw\n",
    "for label in ['Bi', 'Tri']:\n",
    "\n",
    "    for feature in ['hadamard']:\n",
    "\n",
    "        for top, dir, f in os.walk(groups_folder_path + label + \"/\" + feature + \"/\"):\n",
    "            # print(f)\n",
    "            for filename in f:\n",
    "                # print(groups_folder_path + label + \"/\" + feature + \"/\" + filename)\n",
    "                img = cv2.imread(groups_folder_path + label + \"/\" + feature + \"/\" + filename)\n",
    "                img = cv2.resize(img, None, fx=image_size / img.shape[0], fy=image_size / img.shape[1])\n",
    "\n",
    "                X_s.append(img / 256)\n",
    "\n",
    "                if label == 'Bi':\n",
    "                    y.append(0)\n",
    "                else:\n",
    "                    y.append(1)\n",
    "\n",
    "print(X_s[0].shape)\n",
    "# print(X_s)\n",
    "print(len(y))\n",
    "X = np.array(X_s)\n",
    "y = np.array(y)\n",
    "\n",
    "ins = []\n",
    "for i in range(10):\n",
    "    ins.append(inceptionV4_model(X, y))\n",
    "\n",
    "for data in ins:\n",
    "    for d in data:\n",
    "        for j in d:\n",
    "            print(j)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

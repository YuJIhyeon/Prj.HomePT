{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "breeding-flood",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Activation, Input, concatenate, Dropout, Dense, Flatten\n",
    "from keras.layers import MaxPooling2D, Conv2D, AveragePooling2D, BatchNormalization\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.compat.v1.InteractiveSession(config=config)\n",
    "\n",
    "def block_stem(inputs):\n",
    "    net = conv2d(inputs, 32, (3, 3), strides=(2, 2), padding='valid')\n",
    "    net = conv2d(net, 32, (3, 3), padding='valid')\n",
    "    net = conv2d(net, 64, (3, 3))\n",
    "\n",
    "    branch_1 = MaxPooling2D((3, 3), strides=(2, 2), padding='valid')(net)\n",
    "    branch_2 = conv2d(net, 96, (3, 3), strides=(2, 2), padding='valid')\n",
    "\n",
    "    net = concatenate([branch_1, branch_2])\n",
    "\n",
    "    branch_1 = conv2d(net, 64, (1, 1))\n",
    "    branch_1 = conv2d(branch_1, 96, (3, 3), padding='valid')\n",
    "\n",
    "    branch_2 = conv2d(net, 64, (1, 1))\n",
    "    branch_2 = conv2d(branch_2, 64, (7, 1))\n",
    "    branch_2 = conv2d(branch_2, 64, (1, 7))\n",
    "    branch_2 = conv2d(branch_2, 96, (3, 3), padding='valid')\n",
    "\n",
    "    net = concatenate([branch_1, branch_2])\n",
    "\n",
    "    branch_1 = conv2d(net, 192, (3, 3), strides=(2, 2), padding='valid')  # different from the paper\n",
    "    branch_2 = MaxPooling2D((3, 3), strides=(2, 2), padding='valid')(net)\n",
    "\n",
    "    net = concatenate([branch_1, branch_2])\n",
    "\n",
    "    return net\n",
    "\n",
    "\n",
    "def block_inception_a(inputs):\n",
    "    branch_1 = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(inputs)\n",
    "    branch_1 = conv2d(branch_1, 96, (1, 1))\n",
    "\n",
    "    branch_2 = conv2d(inputs, 96, (1, 1))\n",
    "\n",
    "    branch_3 = conv2d(inputs, 64, (1, 1))\n",
    "    branch_3 = conv2d(branch_3, 96, (3, 3))\n",
    "\n",
    "    branch_4 = conv2d(inputs, 64, (1, 1))\n",
    "    branch_4 = conv2d(branch_4, 96, (3, 3))\n",
    "    branch_4 = conv2d(branch_4, 96, (3, 3))\n",
    "\n",
    "    return concatenate([branch_1, branch_2, branch_3, branch_4])\n",
    "\n",
    "\n",
    "def block_inception_b(inputs):\n",
    "    branch_1 = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(inputs)\n",
    "    branch_1 = conv2d(branch_1, 128, (1, 1))\n",
    "\n",
    "    branch_2 = conv2d(inputs, 384, (1, 1))\n",
    "\n",
    "    branch_3 = conv2d(inputs, 192, (1, 1))\n",
    "    branch_3 = conv2d(branch_3, 224, (1, 7))\n",
    "    branch_3 = conv2d(branch_3, 256, (7, 1))  # different from the paper\n",
    "\n",
    "    branch_4 = conv2d(inputs, 192, (1, 1))\n",
    "    branch_4 = conv2d(branch_4, 192, (1, 7))\n",
    "    branch_4 = conv2d(branch_4, 224, (7, 1))\n",
    "    branch_4 = conv2d(branch_4, 224, (1, 7))\n",
    "    branch_4 = conv2d(branch_4, 256, (7, 1))\n",
    "\n",
    "    return concatenate([branch_1, branch_2, branch_3, branch_4])\n",
    "\n",
    "\n",
    "def block_inception_c(inputs):\n",
    "    branch_1 = AveragePooling2D((3, 3), strides=(1, 1), padding='same')(inputs)\n",
    "    branch_1 = conv2d(branch_1, 256, (1, 1))\n",
    "\n",
    "    branch_2 = conv2d(inputs, 256, (1, 1))\n",
    "\n",
    "    branch_3 = conv2d(inputs, 384, (1, 1))\n",
    "    branch_3_1 = conv2d(branch_3, 256, (1, 3))\n",
    "    branch_3_2 = conv2d(branch_3, 256, (3, 1))\n",
    "\n",
    "    branch_4 = conv2d(inputs, 384, (1, 1))\n",
    "    branch_4 = conv2d(branch_4, 448, (1, 3))\n",
    "    branch_4 = conv2d(branch_4, 512, (3, 1))\n",
    "    branch_4_1 = conv2d(branch_4, 256, (3, 1))\n",
    "    branch_4_2 = conv2d(branch_4, 256, (1, 3))\n",
    "\n",
    "    return concatenate([branch_1, branch_2, branch_3_1, branch_3_2, branch_4_1, branch_4_2])\n",
    "\n",
    "\n",
    "def block_reduction_a(inputs):\n",
    "    branch_1 = MaxPooling2D((3, 3), strides=(2, 2), padding='valid')(inputs)\n",
    "\n",
    "    branch_2 = conv2d(inputs, 384, (3, 3), strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch_3 = conv2d(inputs, 192, (1, 1))\n",
    "    branch_3 = conv2d(branch_3, 224, (3, 3))\n",
    "    branch_3 = conv2d(branch_3, 256, (3, 3), strides=(2, 2), padding='valid')\n",
    "\n",
    "    return concatenate([branch_1, branch_2, branch_3])\n",
    "\n",
    "\n",
    "def block_reduction_b(inputs):\n",
    "    branch_1 = MaxPooling2D((3, 3), strides=(2, 2), padding='valid')(inputs)\n",
    "\n",
    "    branch_2 = conv2d(inputs, 192, (1, 1))\n",
    "    branch_2 = conv2d(branch_2, 192, (3, 3), strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch_3 = conv2d(inputs, 256, (1, 1))\n",
    "    branch_3 = conv2d(branch_3, 256, (1, 7))\n",
    "    branch_3 = conv2d(branch_3, 320, (7, 1))\n",
    "    branch_3 = conv2d(branch_3, 320, (3, 3), strides=(2, 2), padding='valid')\n",
    "\n",
    "    return concatenate([branch_1, branch_2, branch_3])\n",
    "\n",
    "\n",
    "def conv2d(net, filters, kernel_size, strides=(1, 1), padding='same'):\n",
    "    net = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding=padding, use_bias=False)(net)\n",
    "    net = BatchNormalization()(net)\n",
    "    net = Activation('relu')(net)\n",
    "    return net\n",
    "\n",
    "def create(classes_num=4):\n",
    "    inputs = Input((227, 227, 3))\n",
    "\n",
    "    # 227 x 227 x 3\n",
    "    net = block_stem(inputs)\n",
    "\n",
    "    # 4 x Inception-A ( Output: 35 x 35 x 384 )\n",
    "    for i in range(4):\n",
    "        net = block_inception_a(net)\n",
    "\n",
    "    # Reduction-A ( Output: 17 x 17 x 1024 )\n",
    "    net = block_reduction_a(net)\n",
    "\n",
    "    # 7 x Inception-B ( Output: 17 x 17 x 1024 )\n",
    "    for i in range(7):\n",
    "        net = block_inception_b(net)\n",
    "\n",
    "    # Reduction-B ( Output: 8 x 8 x 1536 )\n",
    "    net = block_reduction_b(net)\n",
    "\n",
    "    # 3 x Inception-C ( Output: 8 x 8 x 1536 )\n",
    "    for i in range(3):\n",
    "        net = block_inception_c(net)\n",
    "\n",
    "    # Average Pooling ( Output: 1536 )\n",
    "    net = AveragePooling2D((5, 5))(net)\n",
    "\n",
    "    # Dropout ( keep 0.8 )\n",
    "    net = Dropout(0.2)(net)\n",
    "    net = Flatten()(net)\n",
    "\n",
    "    # Output\n",
    "    outputs = Dense(units=classes_num, activation='softmax')(net)\n",
    "\n",
    "    return Model(inputs, outputs, name='Inception-v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "possible-immigration",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inceptionV4_model(X,y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    # validation split\n",
    "\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.1, random_state=10,\n",
    "                                                                    stratify=y_train)\n",
    "    print(len(X_train))\n",
    "\n",
    "\n",
    "    model = create()\n",
    "    model.compile(loss=keras.losses.sparse_categorical_crossentropy, metrics=['accuracy'],\n",
    "                  optimizer=keras.optimizers.SGD(learning_rate=0.01))\n",
    "    model.fit(X_train, y_train, batch_size=16, epochs=10, validation_data=(X_validation, y_validation))\n",
    "    \n",
    "    evaluation = []\n",
    "    evaluation.append(model.evaluate(X_train, y_train, batch_size=16))\n",
    "    evaluation.append(model.evaluate(X_test, y_test, batch_size=16))\n",
    "    \n",
    "    return evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "threaded-turkey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(227, 227, 3)\n",
      "2400\n",
      "1728\n",
      "Epoch 1/10\n",
      "108/108 [==============================] - 54s 217ms/step - loss: 0.3873 - accuracy: 0.8181 - val_loss: 2.3363 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "108/108 [==============================] - 22s 202ms/step - loss: 0.0151 - accuracy: 0.9991 - val_loss: 0.3081 - val_accuracy: 0.8750\n",
      "Epoch 3/10\n",
      "108/108 [==============================] - 22s 206ms/step - loss: 0.0064 - accuracy: 0.9994 - val_loss: 0.0074 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "108/108 [==============================] - 22s 207ms/step - loss: 0.0291 - accuracy: 0.9913 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "108/108 [==============================] - 23s 210ms/step - loss: 0.0149 - accuracy: 0.9975 - val_loss: 0.0114 - val_accuracy: 0.9948\n",
      "Epoch 6/10\n",
      "108/108 [==============================] - 22s 204ms/step - loss: 0.0162 - accuracy: 0.9967 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "108/108 [==============================] - 22s 205ms/step - loss: 0.0040 - accuracy: 0.9997 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "108/108 [==============================] - 22s 203ms/step - loss: 0.0075 - accuracy: 0.9983 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "108/108 [==============================] - 22s 203ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "108/108 [==============================] - 22s 204ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "108/108 [==============================] - 7s 62ms/step - loss: 7.5271e-05 - accuracy: 1.0000\n",
      "30/30 [==============================] - 2s 59ms/step - loss: 1.7563e-04 - accuracy: 1.0000\n",
      "1728\n",
      "Epoch 1/10\n",
      "108/108 [==============================] - 31s 226ms/step - loss: 0.3850 - accuracy: 0.8232 - val_loss: 2.2304 - val_accuracy: 0.4479\n",
      "Epoch 2/10\n",
      "108/108 [==============================] - 23s 210ms/step - loss: 0.0298 - accuracy: 0.9951 - val_loss: 0.6050 - val_accuracy: 0.6406\n",
      "Epoch 3/10\n",
      "108/108 [==============================] - 24s 218ms/step - loss: 0.0179 - accuracy: 0.9959 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "108/108 [==============================] - 23s 215ms/step - loss: 0.0124 - accuracy: 0.9962 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "108/108 [==============================] - 23s 214ms/step - loss: 0.0131 - accuracy: 0.9947 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "108/108 [==============================] - 23s 212ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 6.8728e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "108/108 [==============================] - 23s 215ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 7.4988e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "108/108 [==============================] - 23s 214ms/step - loss: 0.0093 - accuracy: 0.9956 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "108/108 [==============================] - 22s 205ms/step - loss: 0.0033 - accuracy: 0.9997 - val_loss: 0.0068 - val_accuracy: 0.9948\n",
      "Epoch 10/10\n",
      "108/108 [==============================] - 22s 207ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "108/108 [==============================] - 7s 61ms/step - loss: 1.0482e-04 - accuracy: 1.0000\n",
      "30/30 [==============================] - 2s 60ms/step - loss: 1.6438e-04 - accuracy: 1.0000\n",
      "1728\n",
      "Epoch 1/10\n",
      "108/108 [==============================] - 30s 217ms/step - loss: 0.2729 - accuracy: 0.8711 - val_loss: 52.4669 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "108/108 [==============================] - 22s 203ms/step - loss: 0.0243 - accuracy: 0.9952 - val_loss: 0.5348 - val_accuracy: 0.8125\n",
      "Epoch 3/10\n",
      "108/108 [==============================] - 22s 208ms/step - loss: 0.0111 - accuracy: 0.9978 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "108/108 [==============================] - 23s 211ms/step - loss: 0.0069 - accuracy: 0.9995 - val_loss: 4.5024e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "108/108 [==============================] - 22s 207ms/step - loss: 0.0047 - accuracy: 0.9993 - val_loss: 2.3369e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "108/108 [==============================] - 22s 207ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.0778e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "108/108 [==============================] - 22s 206ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.4695e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "108/108 [==============================] - 22s 207ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 8.0588e-05 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "108/108 [==============================] - 22s 208ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 9.4008e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "108/108 [==============================] - 23s 209ms/step - loss: 0.0027 - accuracy: 0.9996 - val_loss: 9.8904e-05 - val_accuracy: 1.0000\n",
      "108/108 [==============================] - 7s 62ms/step - loss: 9.4556e-05 - accuracy: 1.0000\n",
      "30/30 [==============================] - 2s 61ms/step - loss: 9.4122e-05 - accuracy: 1.0000\n",
      "1728\n",
      "Epoch 1/10\n",
      "108/108 [==============================] - 30s 219ms/step - loss: 0.4193 - accuracy: 0.8166 - val_loss: 21.5709 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "108/108 [==============================] - 22s 206ms/step - loss: 0.0204 - accuracy: 0.9944 - val_loss: 0.4236 - val_accuracy: 0.7969\n",
      "Epoch 3/10\n",
      "108/108 [==============================] - 22s 208ms/step - loss: 0.0098 - accuracy: 0.9975 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "108/108 [==============================] - 23s 209ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 4.3236e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "108/108 [==============================] - 22s 204ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.4548e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "108/108 [==============================] - 22s 204ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 1.5095e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "108/108 [==============================] - 22s 204ms/step - loss: 0.0025 - accuracy: 0.9999 - val_loss: 2.6222e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "108/108 [==============================] - 23s 210ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.0633e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "108/108 [==============================] - 22s 208ms/step - loss: 0.0102 - accuracy: 0.9958 - val_loss: 1.5487e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "108/108 [==============================] - 23s 210ms/step - loss: 0.0104 - accuracy: 0.9956 - val_loss: 6.5173e-05 - val_accuracy: 1.0000\n",
      "108/108 [==============================] - 7s 60ms/step - loss: 2.1992e-04 - accuracy: 1.0000\n",
      "30/30 [==============================] - 2s 60ms/step - loss: 8.0621e-05 - accuracy: 1.0000\n",
      "1728\n",
      "Epoch 1/10\n",
      "108/108 [==============================] - 30s 219ms/step - loss: 0.3185 - accuracy: 0.8373 - val_loss: 23.3089 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "108/108 [==============================] - 22s 206ms/step - loss: 0.0283 - accuracy: 0.9922 - val_loss: 3.0379 - val_accuracy: 0.5417\n",
      "Epoch 3/10\n",
      "108/108 [==============================] - 22s 205ms/step - loss: 0.0107 - accuracy: 0.9984 - val_loss: 0.2298 - val_accuracy: 0.9323\n",
      "Epoch 4/10\n",
      "108/108 [==============================] - 22s 206ms/step - loss: 0.0211 - accuracy: 0.9933 - val_loss: 6.9719e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "108/108 [==============================] - 22s 206ms/step - loss: 0.0023 - accuracy: 0.9999 - val_loss: 1.0802e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "108/108 [==============================] - 22s 205ms/step - loss: 0.0092 - accuracy: 0.9985 - val_loss: 8.8813e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "108/108 [==============================] - 22s 207ms/step - loss: 0.0364 - accuracy: 0.9887 - val_loss: 1.5297e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "108/108 [==============================] - 22s 207ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.0411e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "108/108 [==============================] - 22s 205ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 5.7205e-05 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "108/108 [==============================] - 22s 205ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 5.0006e-05 - val_accuracy: 1.0000\n",
      "108/108 [==============================] - 7s 61ms/step - loss: 5.1533e-05 - accuracy: 1.0000\n",
      "30/30 [==============================] - 2s 60ms/step - loss: 4.9149e-05 - accuracy: 1.0000\n",
      "1728\n",
      "Epoch 1/10\n",
      "108/108 [==============================] - 30s 218ms/step - loss: 0.3000 - accuracy: 0.8702 - val_loss: 22.5578 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "108/108 [==============================] - 23s 209ms/step - loss: 0.0202 - accuracy: 0.9962 - val_loss: 18.2294 - val_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "108/108 [==============================] - 22s 208ms/step - loss: 0.0255 - accuracy: 0.9964 - val_loss: 0.0561 - val_accuracy: 0.9896\n",
      "Epoch 4/10\n",
      "108/108 [==============================] - 22s 206ms/step - loss: 0.0090 - accuracy: 0.9986 - val_loss: 0.6704 - val_accuracy: 0.9167\n",
      "Epoch 5/10\n",
      "108/108 [==============================] - 22s 206ms/step - loss: 0.0113 - accuracy: 0.9989 - val_loss: 5.6086e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "108/108 [==============================] - 22s 205ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "108/108 [==============================] - 22s 206ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 2.5370e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "108/108 [==============================] - 22s 207ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.5490e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "108/108 [==============================] - 22s 205ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.1741e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "108/108 [==============================] - 22s 204ms/step - loss: 0.0082 - accuracy: 0.9979 - val_loss: 0.0115 - val_accuracy: 0.9948\n",
      "108/108 [==============================] - 7s 60ms/step - loss: 0.0284 - accuracy: 0.9867\n",
      "30/30 [==============================] - 2s 59ms/step - loss: 0.0331 - accuracy: 0.9937\n",
      "1728\n",
      "Epoch 1/10\n",
      "108/108 [==============================] - 30s 215ms/step - loss: 0.3993 - accuracy: 0.8251 - val_loss: 3.6525 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "108/108 [==============================] - 22s 202ms/step - loss: 0.0469 - accuracy: 0.9861 - val_loss: 0.1245 - val_accuracy: 0.9427\n",
      "Epoch 3/10\n",
      "108/108 [==============================] - 22s 203ms/step - loss: 0.0371 - accuracy: 0.9858 - val_loss: 0.0119 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "108/108 [==============================] - 22s 204ms/step - loss: 0.0162 - accuracy: 0.9978 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "108/108 [==============================] - 22s 203ms/step - loss: 0.0139 - accuracy: 0.9976 - val_loss: 8.0911e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "108/108 [==============================] - 22s 203ms/step - loss: 0.0092 - accuracy: 0.9981 - val_loss: 2.3005e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "108/108 [==============================] - 22s 203ms/step - loss: 0.0151 - accuracy: 0.9956 - val_loss: 0.5441 - val_accuracy: 0.9479\n",
      "Epoch 8/10\n",
      "108/108 [==============================] - 22s 204ms/step - loss: 0.0054 - accuracy: 0.9991 - val_loss: 0.0164 - val_accuracy: 0.9948\n",
      "Epoch 9/10\n",
      "108/108 [==============================] - 22s 205ms/step - loss: 0.0164 - accuracy: 0.9941 - val_loss: 0.0493 - val_accuracy: 0.9948\n",
      "Epoch 10/10\n",
      "108/108 [==============================] - 22s 203ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.0269 - val_accuracy: 0.9948\n",
      "108/108 [==============================] - 7s 63ms/step - loss: 1.1794e-04 - accuracy: 1.0000\n",
      "30/30 [==============================] - 2s 58ms/step - loss: 2.9427e-04 - accuracy: 1.0000\n",
      "1728\n",
      "Epoch 1/10\n",
      "108/108 [==============================] - 30s 216ms/step - loss: 0.3686 - accuracy: 0.8381 - val_loss: 3.4342 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "108/108 [==============================] - 22s 203ms/step - loss: 0.0306 - accuracy: 0.9914 - val_loss: 0.0771 - val_accuracy: 0.9896\n",
      "Epoch 3/10\n",
      "108/108 [==============================] - 22s 204ms/step - loss: 0.0096 - accuracy: 0.9991 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "108/108 [==============================] - 22s 204ms/step - loss: 0.0052 - accuracy: 0.9993 - val_loss: 0.0104 - val_accuracy: 0.9948\n",
      "Epoch 5/10\n",
      "108/108 [==============================] - 22s 204ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "108/108 [==============================] - 22s 205ms/step - loss: 0.0185 - accuracy: 0.9962 - val_loss: 0.1234 - val_accuracy: 0.9583\n",
      "Epoch 7/10\n",
      "108/108 [==============================] - 22s 204ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 0.9948\n",
      "Epoch 8/10\n",
      "108/108 [==============================] - 22s 204ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "108/108 [==============================] - 22s 205ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 8.3074e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "108/108 [==============================] - 22s 204ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "108/108 [==============================] - 7s 60ms/step - loss: 0.0279 - accuracy: 0.9948\n",
      "30/30 [==============================] - 2s 60ms/step - loss: 0.0320 - accuracy: 0.9937\n",
      "1728\n",
      "Epoch 1/10\n",
      "108/108 [==============================] - 29s 217ms/step - loss: 0.4170 - accuracy: 0.8128 - val_loss: 3.9341 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "108/108 [==============================] - 22s 204ms/step - loss: 0.0370 - accuracy: 0.9932 - val_loss: 2.1398 - val_accuracy: 0.5729\n",
      "Epoch 3/10\n",
      "108/108 [==============================] - 22s 206ms/step - loss: 0.0188 - accuracy: 0.9935 - val_loss: 0.0149 - val_accuracy: 0.9948\n",
      "Epoch 4/10\n",
      "108/108 [==============================] - 22s 204ms/step - loss: 0.0090 - accuracy: 0.9987 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "108/108 [==============================] - 22s 204ms/step - loss: 0.0269 - accuracy: 0.9941 - val_loss: 0.0103 - val_accuracy: 0.9948\n",
      "Epoch 6/10\n",
      "108/108 [==============================] - 22s 204ms/step - loss: 0.0057 - accuracy: 0.9996 - val_loss: 5.2069e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "108/108 [==============================] - 22s 204ms/step - loss: 0.0115 - accuracy: 0.9991 - val_loss: 1.7148e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "108/108 [==============================] - 22s 204ms/step - loss: 0.0049 - accuracy: 0.9989 - val_loss: 2.9699e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "108/108 [==============================] - 22s 204ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.1944e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "108/108 [==============================] - 22s 204ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 6.7155e-05 - val_accuracy: 1.0000\n",
      "108/108 [==============================] - 6s 60ms/step - loss: 1.2987e-04 - accuracy: 1.0000\n",
      "30/30 [==============================] - 2s 59ms/step - loss: 7.2863e-05 - accuracy: 1.0000\n",
      "1728\n",
      "Epoch 1/10\n",
      "108/108 [==============================] - 29s 216ms/step - loss: 0.3790 - accuracy: 0.8246 - val_loss: 20.7471 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "108/108 [==============================] - 22s 204ms/step - loss: 0.0260 - accuracy: 0.9964 - val_loss: 0.7711 - val_accuracy: 0.6510\n",
      "Epoch 3/10\n",
      "108/108 [==============================] - 22s 204ms/step - loss: 0.0278 - accuracy: 0.9906 - val_loss: 0.0425 - val_accuracy: 0.9896\n",
      "Epoch 4/10\n",
      "108/108 [==============================] - 22s 204ms/step - loss: 0.0183 - accuracy: 0.9943 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "108/108 [==============================] - 22s 204ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.5302e-04 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "108/108 [==============================] - 22s 204ms/step - loss: 0.0027 - accuracy: 0.9999 - val_loss: 3.4797e-04 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "108/108 [==============================] - 22s 204ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.3632e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "108/108 [==============================] - 22s 204ms/step - loss: 0.0149 - accuracy: 0.9969 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "108/108 [==============================] - 22s 204ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.3441 - val_accuracy: 0.9062\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 22s 204ms/step - loss: 0.0343 - accuracy: 0.9930 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "108/108 [==============================] - 7s 60ms/step - loss: 0.0028 - accuracy: 0.9994\n",
      "30/30 [==============================] - 2s 60ms/step - loss: 4.1219e-04 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "image_size = 227\n",
    "\n",
    "groups_folder_path = '../Data/AAFT_0/'\n",
    "\n",
    "X_s = []\n",
    "\n",
    "y = []\n",
    "# auto_corr   hadamard     midAng    striping_color   striping_bw     striping_midAng_color     striping_midAng_bw\n",
    "for label in ['Bi', 'Tri', 'Hammer', 'Rvcurl']:\n",
    "\n",
    "    for feature in ['striping_color']:\n",
    "\n",
    "        for top, dir, f in os.walk(groups_folder_path + label + \"/\" + feature + \"/\"):\n",
    "            # print(f)\n",
    "            for filename in f:\n",
    "                # print(groups_folder_path + label + \"/\" + feature + \"/\" + filename)\n",
    "                img = cv2.imread(groups_folder_path + label + \"/\" + feature + \"/\" + filename)\n",
    "                img = cv2.resize(img, None, fx=image_size / img.shape[0], fy=image_size / img.shape[1])\n",
    "\n",
    "                X_s.append(img / 256)\n",
    "\n",
    "                if label == 'Bi':\n",
    "                    y.append(0)\n",
    "                elif label =='Tri'\n",
    "                    y.append(1)\n",
    "                elif label == 'Hammer'\n",
    "                    y.append(2)\n",
    "                else:\n",
    "                    y.append(3)\n",
    "\n",
    "print(X_s[0].shape)\n",
    "# print(X_s)\n",
    "print(len(y))\n",
    "X = np.array(X_s)\n",
    "y = np.array(y)\n",
    "\n",
    "ins = []\n",
    "for i in range(2):\n",
    "    ins.append(inceptionV4_model(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "warming-computer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.527112757088616e-05\n",
      "1.0\n",
      "0.0001756283745635301\n",
      "1.0\n",
      "0.00010482055222382769\n",
      "1.0\n",
      "0.00016437801241409034\n",
      "1.0\n",
      "9.455556573811918e-05\n",
      "1.0\n",
      "9.412155486643314e-05\n",
      "1.0\n",
      "0.00021991896210238338\n",
      "1.0\n",
      "8.062136475928128e-05\n",
      "1.0\n",
      "5.153284655534662e-05\n",
      "1.0\n",
      "4.91494829475414e-05\n",
      "1.0\n",
      "0.028361642733216286\n",
      "0.9866898059844971\n",
      "0.03309622406959534\n",
      "0.9937499761581421\n",
      "0.00011794337478931993\n",
      "1.0\n",
      "0.00029426676337607205\n",
      "1.0\n",
      "0.027872655540704727\n",
      "0.9947916865348816\n",
      "0.03199278563261032\n",
      "0.9937499761581421\n",
      "0.00012986507499590516\n",
      "1.0\n",
      "7.286288018804044e-05\n",
      "1.0\n",
      "0.0027727666310966015\n",
      "0.9994212985038757\n",
      "0.0004121925448998809\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for data in ins:\n",
    "    print(data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clean-frost",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in ins:\n",
    "    print(data[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "appreciated-latitude",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(227, 227, 3)\n",
      "480\n",
      "345\n",
      "Epoch 1/10\n",
      "22/22 [==============================] - 42s 2s/step - loss: 0.5633 - accuracy: 0.7192 - val_loss: 20.4594 - val_accuracy: 0.5128\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 4s 204ms/step - loss: 0.2846 - accuracy: 0.9134 - val_loss: 27.2948 - val_accuracy: 0.4872\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 4s 203ms/step - loss: 0.0983 - accuracy: 0.9712 - val_loss: 0.3002 - val_accuracy: 0.8718\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 4s 204ms/step - loss: 0.0335 - accuracy: 0.9937 - val_loss: 1.9518 - val_accuracy: 0.4872\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 4s 204ms/step - loss: 0.0158 - accuracy: 0.9983 - val_loss: 0.9227 - val_accuracy: 0.4872\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 4s 204ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.5124 - val_accuracy: 0.4872\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 4s 204ms/step - loss: 0.1371 - accuracy: 0.9767 - val_loss: 1.9297 - val_accuracy: 0.4615\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 4s 204ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.8765 - val_accuracy: 0.5385\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 4s 203ms/step - loss: 0.0056 - accuracy: 0.9995 - val_loss: 1.3234 - val_accuracy: 0.5128\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 4s 204ms/step - loss: 0.0870 - accuracy: 0.9804 - val_loss: 1.1015 - val_accuracy: 0.6667\n",
      "22/22 [==============================] - 1s 60ms/step - loss: 1.0605 - accuracy: 0.6754\n",
      "6/6 [==============================] - 2s 59ms/step - loss: 1.1162 - accuracy: 0.6667\n",
      "345\n",
      "Epoch 1/10\n",
      "22/22 [==============================] - 12s 268ms/step - loss: 0.6126 - accuracy: 0.6913 - val_loss: 380.7961 - val_accuracy: 0.5128\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 4s 203ms/step - loss: 0.2447 - accuracy: 0.9133 - val_loss: 55.9186 - val_accuracy: 0.5128\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 4s 203ms/step - loss: 0.0464 - accuracy: 0.9985 - val_loss: 34.9597 - val_accuracy: 0.5128\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 4s 203ms/step - loss: 0.0696 - accuracy: 0.9726 - val_loss: 21.4927 - val_accuracy: 0.5128\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 4s 203ms/step - loss: 0.0252 - accuracy: 0.9986 - val_loss: 6.7444 - val_accuracy: 0.5128\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 5s 210ms/step - loss: 0.0287 - accuracy: 0.9980 - val_loss: 14.3392 - val_accuracy: 0.5128\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 4s 203ms/step - loss: 0.1411 - accuracy: 0.9396 - val_loss: 3.9317 - val_accuracy: 0.5128\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 4s 202ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 3.2655 - val_accuracy: 0.5128\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 4s 201ms/step - loss: 0.0118 - accuracy: 0.9965 - val_loss: 1.8320 - val_accuracy: 0.6154\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 4s 201ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.6188 - val_accuracy: 0.6667\n",
      "22/22 [==============================] - 1s 59ms/step - loss: 1.5394 - accuracy: 0.6609\n",
      "6/6 [==============================] - 2s 59ms/step - loss: 1.7672 - accuracy: 0.6667\n",
      "345\n",
      "Epoch 1/10\n",
      "22/22 [==============================] - 12s 265ms/step - loss: 0.7196 - accuracy: 0.5791 - val_loss: 155.2386 - val_accuracy: 0.5128\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 4s 201ms/step - loss: 0.3156 - accuracy: 0.8816 - val_loss: 36.3263 - val_accuracy: 0.4872\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 4s 201ms/step - loss: 0.2057 - accuracy: 0.9532 - val_loss: 13.9673 - val_accuracy: 0.5128\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 4s 201ms/step - loss: 0.0654 - accuracy: 0.9837 - val_loss: 6.3368 - val_accuracy: 0.5128\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 4s 202ms/step - loss: 0.0293 - accuracy: 0.9943 - val_loss: 1.0457 - val_accuracy: 0.5128\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 4s 201ms/step - loss: 0.0294 - accuracy: 0.9920 - val_loss: 0.0229 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 4s 202ms/step - loss: 0.0223 - accuracy: 0.9969 - val_loss: 0.1254 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 4s 202ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 0.1342 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 4s 202ms/step - loss: 0.0186 - accuracy: 0.9985 - val_loss: 0.1831 - val_accuracy: 0.9487\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 4s 202ms/step - loss: 0.0088 - accuracy: 0.9990 - val_loss: 0.4065 - val_accuracy: 0.8205\n",
      "22/22 [==============================] - 1s 57ms/step - loss: 0.3320 - accuracy: 0.9014\n",
      "6/6 [==============================] - 2s 59ms/step - loss: 0.3825 - accuracy: 0.8333\n",
      "345\n",
      "Epoch 1/10\n",
      "22/22 [==============================] - 12s 267ms/step - loss: 0.6446 - accuracy: 0.6831 - val_loss: 130.5741 - val_accuracy: 0.4872\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 4s 203ms/step - loss: 0.1546 - accuracy: 0.9779 - val_loss: 43.1343 - val_accuracy: 0.4872\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 4s 202ms/step - loss: 0.0440 - accuracy: 0.9968 - val_loss: 23.1300 - val_accuracy: 0.4872\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 4s 202ms/step - loss: 0.0280 - accuracy: 0.9956 - val_loss: 11.3526 - val_accuracy: 0.4872\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 4s 202ms/step - loss: 0.0457 - accuracy: 0.9945 - val_loss: 13.7608 - val_accuracy: 0.4872\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 4s 203ms/step - loss: 0.0205 - accuracy: 0.9978 - val_loss: 4.9276 - val_accuracy: 0.4872\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 4s 203ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 5.7050 - val_accuracy: 0.4872\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 4s 203ms/step - loss: 0.0314 - accuracy: 0.9955 - val_loss: 2.6460 - val_accuracy: 0.4615\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 4s 203ms/step - loss: 0.0160 - accuracy: 0.9962 - val_loss: 1.1545 - val_accuracy: 0.4872\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 4s 203ms/step - loss: 0.0269 - accuracy: 1.0000 - val_loss: 0.3114 - val_accuracy: 0.8462\n",
      "22/22 [==============================] - 1s 59ms/step - loss: 0.2674 - accuracy: 0.8957\n",
      "6/6 [==============================] - 2s 59ms/step - loss: 0.3157 - accuracy: 0.8646\n",
      "345\n",
      "Epoch 1/10\n",
      "22/22 [==============================] - 12s 270ms/step - loss: 0.6409 - accuracy: 0.6209 - val_loss: 105.9614 - val_accuracy: 0.4872\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 4s 202ms/step - loss: 0.1574 - accuracy: 0.9509 - val_loss: 32.7245 - val_accuracy: 0.4872\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 4s 203ms/step - loss: 0.1082 - accuracy: 0.9655 - val_loss: 16.3184 - val_accuracy: 0.4872\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 4s 202ms/step - loss: 0.0375 - accuracy: 0.9960 - val_loss: 7.3187 - val_accuracy: 0.4872\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 4s 202ms/step - loss: 0.0589 - accuracy: 0.9850 - val_loss: 4.5905 - val_accuracy: 0.4872\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 4s 202ms/step - loss: 0.0295 - accuracy: 0.9898 - val_loss: 2.2152 - val_accuracy: 0.6410\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 4s 202ms/step - loss: 0.0082 - accuracy: 0.9987 - val_loss: 1.3096 - val_accuracy: 0.8205\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 4s 203ms/step - loss: 0.0151 - accuracy: 0.9974 - val_loss: 1.3576 - val_accuracy: 0.8462\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 4s 203ms/step - loss: 0.0182 - accuracy: 0.9953 - val_loss: 1.5014 - val_accuracy: 0.8462\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 4s 202ms/step - loss: 0.0079 - accuracy: 0.9997 - val_loss: 1.1891 - val_accuracy: 0.8462\n",
      "22/22 [==============================] - 1s 59ms/step - loss: 0.3802 - accuracy: 0.8870\n",
      "6/6 [==============================] - 2s 59ms/step - loss: 0.9597 - accuracy: 0.7917\n",
      "345\n",
      "Epoch 1/10\n",
      "22/22 [==============================] - 12s 267ms/step - loss: 0.6952 - accuracy: 0.6401 - val_loss: 597.6195 - val_accuracy: 0.4872\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 4s 203ms/step - loss: 0.3002 - accuracy: 0.9193 - val_loss: 114.8938 - val_accuracy: 0.4872\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 4s 203ms/step - loss: 0.2213 - accuracy: 0.9422 - val_loss: 2.5184 - val_accuracy: 0.5128\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 4s 203ms/step - loss: 0.0677 - accuracy: 0.9877 - val_loss: 7.0411 - val_accuracy: 0.5128\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 4s 203ms/step - loss: 0.0486 - accuracy: 0.9978 - val_loss: 0.0955 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 4s 203ms/step - loss: 0.0335 - accuracy: 0.9843 - val_loss: 0.9676 - val_accuracy: 0.5128\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 4s 203ms/step - loss: 0.0330 - accuracy: 0.9878 - val_loss: 0.3039 - val_accuracy: 0.9231\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 4s 203ms/step - loss: 0.0540 - accuracy: 0.9855 - val_loss: 0.1774 - val_accuracy: 0.9744\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 4s 203ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 0.1177 - val_accuracy: 0.9744\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 4s 203ms/step - loss: 0.0124 - accuracy: 0.9995 - val_loss: 0.0872 - val_accuracy: 0.9744\n",
      "22/22 [==============================] - 1s 59ms/step - loss: 0.0842 - accuracy: 0.9710\n",
      "6/6 [==============================] - 2s 59ms/step - loss: 0.1325 - accuracy: 0.9271\n",
      "345\n",
      "Epoch 1/10\n",
      "22/22 [==============================] - 12s 265ms/step - loss: 0.6949 - accuracy: 0.5758 - val_loss: 5.4115 - val_accuracy: 0.5128\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 4s 202ms/step - loss: 0.1686 - accuracy: 0.9689 - val_loss: 4.5876 - val_accuracy: 0.4872\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 4s 202ms/step - loss: 0.0850 - accuracy: 0.9698 - val_loss: 0.5973 - val_accuracy: 0.7436\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 4s 202ms/step - loss: 0.0867 - accuracy: 0.9761 - val_loss: 0.1319 - val_accuracy: 0.9744\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 4s 202ms/step - loss: 0.0130 - accuracy: 0.9995 - val_loss: 8.0540 - val_accuracy: 0.4872\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 4s 202ms/step - loss: 0.0426 - accuracy: 0.9902 - val_loss: 1.2619 - val_accuracy: 0.5128\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 4s 203ms/step - loss: 0.0097 - accuracy: 0.9990 - val_loss: 0.1619 - val_accuracy: 0.9487\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 4s 203ms/step - loss: 0.0136 - accuracy: 0.9985 - val_loss: 2.3569 - val_accuracy: 0.4872\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 4s 204ms/step - loss: 0.0221 - accuracy: 0.9821 - val_loss: 0.2018 - val_accuracy: 0.8462\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 4s 203ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 0.1412 - val_accuracy: 0.9231\n",
      "22/22 [==============================] - 1s 59ms/step - loss: 0.1474 - accuracy: 0.9623\n",
      "6/6 [==============================] - 2s 59ms/step - loss: 0.2164 - accuracy: 0.9062\n",
      "345\n",
      "Epoch 1/10\n",
      "22/22 [==============================] - 12s 266ms/step - loss: 0.7594 - accuracy: 0.6218 - val_loss: 32.1486 - val_accuracy: 0.5128\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 4s 202ms/step - loss: 0.1747 - accuracy: 0.9471 - val_loss: 5.8255 - val_accuracy: 0.5128\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 4s 202ms/step - loss: 0.1621 - accuracy: 0.9648 - val_loss: 2.8214 - val_accuracy: 0.5128\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 4s 203ms/step - loss: 0.0450 - accuracy: 0.9940 - val_loss: 7.7724 - val_accuracy: 0.5128\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 4s 202ms/step - loss: 0.0788 - accuracy: 0.9744 - val_loss: 2.3778 - val_accuracy: 0.5128\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 4s 203ms/step - loss: 0.1246 - accuracy: 0.9672 - val_loss: 4.3153 - val_accuracy: 0.5128\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 4s 203ms/step - loss: 0.0214 - accuracy: 0.9968 - val_loss: 2.8449 - val_accuracy: 0.5897\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 4s 203ms/step - loss: 0.0360 - accuracy: 0.9914 - val_loss: 1.0612 - val_accuracy: 0.6410\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 4s 203ms/step - loss: 0.0155 - accuracy: 0.9963 - val_loss: 0.5159 - val_accuracy: 0.8718\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 4s 203ms/step - loss: 0.0250 - accuracy: 0.9975 - val_loss: 3.1603 - val_accuracy: 0.4872\n",
      "22/22 [==============================] - 1s 59ms/step - loss: 2.2184 - accuracy: 0.5014\n",
      "6/6 [==============================] - 2s 59ms/step - loss: 2.5568 - accuracy: 0.5000\n",
      "345\n",
      "Epoch 1/10\n",
      "22/22 [==============================] - 12s 271ms/step - loss: 0.7863 - accuracy: 0.6075 - val_loss: 238.5875 - val_accuracy: 0.4872\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 4s 202ms/step - loss: 0.1939 - accuracy: 0.9500 - val_loss: 82.4687 - val_accuracy: 0.4872\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 4s 202ms/step - loss: 0.0505 - accuracy: 0.9937 - val_loss: 38.4663 - val_accuracy: 0.4872\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 4s 202ms/step - loss: 0.0434 - accuracy: 0.9926 - val_loss: 20.0586 - val_accuracy: 0.4872\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 4s 202ms/step - loss: 0.0220 - accuracy: 0.9965 - val_loss: 14.9723 - val_accuracy: 0.4872\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 4s 203ms/step - loss: 0.0539 - accuracy: 0.9795 - val_loss: 13.1705 - val_accuracy: 0.4872\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 4s 203ms/step - loss: 0.0189 - accuracy: 0.9948 - val_loss: 9.3773 - val_accuracy: 0.4872\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 4s 203ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 6.7556 - val_accuracy: 0.4872\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 4s 203ms/step - loss: 0.0369 - accuracy: 0.9896 - val_loss: 6.5941 - val_accuracy: 0.4103\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 4s 202ms/step - loss: 0.0671 - accuracy: 0.9695 - val_loss: 4.8666 - val_accuracy: 0.3333\n",
      "22/22 [==============================] - 1s 60ms/step - loss: 3.8203 - accuracy: 0.3130\n",
      "6/6 [==============================] - 2s 59ms/step - loss: 3.9689 - accuracy: 0.3854\n",
      "345\n",
      "Epoch 1/10\n",
      "22/22 [==============================] - 12s 265ms/step - loss: 0.6280 - accuracy: 0.6237 - val_loss: 26.1090 - val_accuracy: 0.4872\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 4s 202ms/step - loss: 0.1919 - accuracy: 0.9337 - val_loss: 0.8028 - val_accuracy: 0.5128\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 4s 202ms/step - loss: 0.0372 - accuracy: 0.9990 - val_loss: 2.7867 - val_accuracy: 0.5128\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 4s 202ms/step - loss: 0.0559 - accuracy: 0.9899 - val_loss: 2.7818 - val_accuracy: 0.4872\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 4s 202ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 0.5513 - val_accuracy: 0.6410\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 4s 202ms/step - loss: 0.0210 - accuracy: 0.9931 - val_loss: 0.3042 - val_accuracy: 0.9231\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 4s 203ms/step - loss: 0.1144 - accuracy: 0.9762 - val_loss: 18.2276 - val_accuracy: 0.4872\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 4s 203ms/step - loss: 0.0476 - accuracy: 0.9787 - val_loss: 0.0729 - val_accuracy: 0.9744\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 4s 203ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.0737 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 4s 202ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 0.0538 - val_accuracy: 1.0000\n",
      "22/22 [==============================] - 1s 59ms/step - loss: 0.0660 - accuracy: 0.9971\n",
      "6/6 [==============================] - 2s 59ms/step - loss: 0.0885 - accuracy: 0.9896\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "groups_folder_path = '../Data/resultVecsFigs/AAFT_4/'\n",
    "X_s = []\n",
    "y = []\n",
    "# auto_corr   hadamard     midAng    striping_color   striping_bw     striping_midAng_color     striping_midAng_bw\n",
    "for label in ['Bi', 'Tri']:\n",
    "\n",
    "    for feature in ['hadamard']:\n",
    "\n",
    "        for top, dir, f in os.walk(groups_folder_path + label + \"/\" + feature + \"/\"):\n",
    "            # print(f)\n",
    "            for filename in f:\n",
    "                # print(groups_folder_path + label + \"/\" + feature + \"/\" + filename)\n",
    "                img = cv2.imread(groups_folder_path + label + \"/\" + feature + \"/\" + filename)\n",
    "                img = cv2.resize(img, None, fx=image_size / img.shape[0], fy=image_size / img.shape[1])\n",
    "\n",
    "                X_s.append(img / 256)\n",
    "\n",
    "                if label == 'Bi':\n",
    "                    y.append(0)\n",
    "                else:\n",
    "                    y.append(1)\n",
    "\n",
    "print(X_s[0].shape)\n",
    "# print(X_s)\n",
    "print(len(y))\n",
    "X = np.array(X_s)\n",
    "y = np.array(y)\n",
    "\n",
    "ins = []\n",
    "for i in range(10):\n",
    "    ins.append(inceptionV4_model(X, y))\n",
    "\n",
    "for data in ins:\n",
    "    for d in data:\n",
    "        for j in d:\n",
    "            print(j)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "incorporate-workshop",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "talented-messaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "session = tf.compat.v1.InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "homeless-spouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def NN():\n",
    "    \n",
    "    evaluation = []\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    # validation split\n",
    "\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.1, random_state=10, stratify=y_train)\n",
    "    Neural_Network = keras.models.Sequential([\n",
    "    # input layer\n",
    "    keras.layers.Dense(5, activation='relu', input_shape=(len(X_train[0]),)),\n",
    "\n",
    "    # hidden layer 1\n",
    "    #keras.layers.Dense(256, activation='relu'),\n",
    "\n",
    "    # hidden layer 2\n",
    "    #keras.layers.Dense(128, activation='relu'),\n",
    "\n",
    "    # output layer\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "    ])\n",
    "    #Neural_Network.summary()\n",
    "    Neural_Network.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    Neural_Network.fit(X_train, y_train, epochs=10, batch_size=16, verbose=1)\n",
    "    evaluation.append(Neural_Network.evaluate(X_train, y_train, batch_size=16))\n",
    "    evaluation.append(Neural_Network.evaluate(X_test, y_test, batch_size=16))\n",
    "    return evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "variable-brighton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n",
      "Train on 432 samples\n",
      "Epoch 1/10\n",
      "432/432 [==============================] - 0s 820us/sample - loss: 0.6286 - accuracy: 0.4884\n",
      "Epoch 2/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.4652 - accuracy: 0.8102\n",
      "Epoch 3/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.4022 - accuracy: 0.8935\n",
      "Epoch 4/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.3628 - accuracy: 0.9583\n",
      "Epoch 5/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.3367 - accuracy: 0.9606\n",
      "Epoch 6/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.3160 - accuracy: 0.9907\n",
      "Epoch 7/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.2991 - accuracy: 0.9931\n",
      "Epoch 8/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.2839 - accuracy: 0.9954\n",
      "Epoch 9/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.2711 - accuracy: 0.9954\n",
      "Epoch 10/10\n",
      "432/432 [==============================] - 0s 60us/sample - loss: 0.2590 - accuracy: 0.9977\n",
      "432/432 [==============================] - 0s 134us/sample - loss: 0.2531 - accuracy: 1.0000\n",
      "120/120 [==============================] - 0s 400us/sample - loss: 0.2567 - accuracy: 0.9917\n",
      "Train on 432 samples\n",
      "Epoch 1/10\n",
      "432/432 [==============================] - 0s 336us/sample - loss: 0.2811 - accuracy: 0.9954\n",
      "Epoch 2/10\n",
      "432/432 [==============================] - 0s 67us/sample - loss: 0.1175 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.0604 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.0372 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.0255 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.0189 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "432/432 [==============================] - 0s 64us/sample - loss: 0.0147 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.0093 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "432/432 [==============================] - 0s 67us/sample - loss: 0.0077 - accuracy: 1.0000\n",
      "432/432 [==============================] - 0s 132us/sample - loss: 0.0070 - accuracy: 1.0000\n",
      "120/120 [==============================] - 0s 400us/sample - loss: 0.0073 - accuracy: 1.0000\n",
      "Train on 432 samples\n",
      "Epoch 1/10\n",
      "432/432 [==============================] - 0s 336us/sample - loss: 0.5756 - accuracy: 0.7778\n",
      "Epoch 2/10\n",
      "432/432 [==============================] - 0s 67us/sample - loss: 0.3518 - accuracy: 0.9653\n",
      "Epoch 3/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.2157 - accuracy: 0.9931\n",
      "Epoch 4/10\n",
      "432/432 [==============================] - 0s 70us/sample - loss: 0.1401 - accuracy: 0.9977\n",
      "Epoch 5/10\n",
      "432/432 [==============================] - 0s 67us/sample - loss: 0.0962 - accuracy: 0.9977\n",
      "Epoch 6/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.0716 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "432/432 [==============================] - 0s 67us/sample - loss: 0.0540 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.0427 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.0347 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "432/432 [==============================] - 0s 67us/sample - loss: 0.0286 - accuracy: 1.0000\n",
      "432/432 [==============================] - 0s 130us/sample - loss: 0.0261 - accuracy: 1.0000\n",
      "120/120 [==============================] - 0s 400us/sample - loss: 0.0267 - accuracy: 1.0000\n",
      "Train on 432 samples\n",
      "Epoch 1/10\n",
      "432/432 [==============================] - 0s 334us/sample - loss: 0.5328 - accuracy: 0.7500\n",
      "Epoch 2/10\n",
      "432/432 [==============================] - 0s 60us/sample - loss: 0.4384 - accuracy: 0.8866\n",
      "Epoch 3/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.3836 - accuracy: 0.9398\n",
      "Epoch 4/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.3497 - accuracy: 0.9769\n",
      "Epoch 5/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.3243 - accuracy: 0.9815\n",
      "Epoch 6/10\n",
      "432/432 [==============================] - 0s 60us/sample - loss: 0.3048 - accuracy: 0.9907\n",
      "Epoch 7/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.2882 - accuracy: 0.9977\n",
      "Epoch 8/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.2741 - accuracy: 0.9954\n",
      "Epoch 9/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.2613 - accuracy: 0.9977\n",
      "Epoch 10/10\n",
      "432/432 [==============================] - 0s 60us/sample - loss: 0.2494 - accuracy: 1.0000\n",
      "432/432 [==============================] - 0s 132us/sample - loss: 0.2436 - accuracy: 1.0000\n",
      "120/120 [==============================] - 0s 400us/sample - loss: 0.2431 - accuracy: 1.0000\n",
      "Train on 432 samples\n",
      "Epoch 1/10\n",
      "432/432 [==============================] - 0s 331us/sample - loss: 0.5342 - accuracy: 0.9213\n",
      "Epoch 2/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.3342 - accuracy: 0.9977\n",
      "Epoch 3/10\n",
      "432/432 [==============================] - 0s 60us/sample - loss: 0.1989 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "432/432 [==============================] - 0s 60us/sample - loss: 0.1159 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.0719 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "432/432 [==============================] - 0s 60us/sample - loss: 0.0483 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "432/432 [==============================] - 0s 60us/sample - loss: 0.0348 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.0264 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "432/432 [==============================] - 0s 60us/sample - loss: 0.0205 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "432/432 [==============================] - 0s 60us/sample - loss: 0.0165 - accuracy: 1.0000\n",
      "432/432 [==============================] - 0s 130us/sample - loss: 0.0149 - accuracy: 1.0000\n",
      "120/120 [==============================] - 0s 400us/sample - loss: 0.0158 - accuracy: 1.0000\n",
      "Train on 432 samples\n",
      "Epoch 1/10\n",
      "432/432 [==============================] - 0s 336us/sample - loss: 0.6398 - accuracy: 0.6042\n",
      "Epoch 2/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.3394 - accuracy: 0.9606\n",
      "Epoch 3/10\n",
      "432/432 [==============================] - 0s 60us/sample - loss: 0.1873 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "432/432 [==============================] - 0s 67us/sample - loss: 0.1149 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "432/432 [==============================] - 0s 60us/sample - loss: 0.0785 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "432/432 [==============================] - 0s 60us/sample - loss: 0.0572 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.0440 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.0351 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "432/432 [==============================] - 0s 60us/sample - loss: 0.0286 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.0239 - accuracy: 1.0000\n",
      "432/432 [==============================] - 0s 137us/sample - loss: 0.0217 - accuracy: 1.0000\n",
      "120/120 [==============================] - 0s 384us/sample - loss: 0.0214 - accuracy: 1.0000\n",
      "Train on 432 samples\n",
      "Epoch 1/10\n",
      "432/432 [==============================] - 0s 324us/sample - loss: 0.5814 - accuracy: 0.7199\n",
      "Epoch 2/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.2413 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.1387 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.0904 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.0624 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.0463 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "432/432 [==============================] - 0s 60us/sample - loss: 0.0356 - accuracy: 1.0000\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432/432 [==============================] - 0s 65us/sample - loss: 0.0281 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.0229 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "432/432 [==============================] - 0s 60us/sample - loss: 0.0192 - accuracy: 1.0000\n",
      "432/432 [==============================] - 0s 127us/sample - loss: 0.0175 - accuracy: 1.0000\n",
      "120/120 [==============================] - 0s 392us/sample - loss: 0.0194 - accuracy: 1.0000\n",
      "Train on 432 samples\n",
      "Epoch 1/10\n",
      "432/432 [==============================] - 0s 331us/sample - loss: 0.6578 - accuracy: 0.7130\n",
      "Epoch 2/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.5822 - accuracy: 0.9398\n",
      "Epoch 3/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.4631 - accuracy: 0.9884\n",
      "Epoch 4/10\n",
      "432/432 [==============================] - 0s 60us/sample - loss: 0.3272 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.2161 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "432/432 [==============================] - 0s 60us/sample - loss: 0.1434 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.0991 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.0719 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.0547 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.0431 - accuracy: 1.0000\n",
      "432/432 [==============================] - 0s 130us/sample - loss: 0.0383 - accuracy: 1.0000\n",
      "120/120 [==============================] - 0s 409us/sample - loss: 0.0390 - accuracy: 1.0000\n",
      "Train on 432 samples\n",
      "Epoch 1/10\n",
      "432/432 [==============================] - 0s 334us/sample - loss: 0.6331 - accuracy: 0.6227\n",
      "Epoch 2/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.5199 - accuracy: 0.7824\n",
      "Epoch 3/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.4534 - accuracy: 0.8657\n",
      "Epoch 4/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.4071 - accuracy: 0.9259\n",
      "Epoch 5/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.3729 - accuracy: 0.9375\n",
      "Epoch 6/10\n",
      "432/432 [==============================] - 0s 60us/sample - loss: 0.3460 - accuracy: 0.9537\n",
      "Epoch 7/10\n",
      "432/432 [==============================] - 0s 60us/sample - loss: 0.3231 - accuracy: 0.9745\n",
      "Epoch 8/10\n",
      "432/432 [==============================] - 0s 60us/sample - loss: 0.3035 - accuracy: 0.9745\n",
      "Epoch 9/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.2866 - accuracy: 0.9792\n",
      "Epoch 10/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.2715 - accuracy: 0.9792\n",
      "432/432 [==============================] - 0s 130us/sample - loss: 0.2641 - accuracy: 0.9861\n",
      "120/120 [==============================] - 0s 400us/sample - loss: 0.2657 - accuracy: 0.9833\n",
      "Train on 432 samples\n",
      "Epoch 1/10\n",
      "432/432 [==============================] - 0s 327us/sample - loss: 0.6141 - accuracy: 0.7569\n",
      "Epoch 2/10\n",
      "432/432 [==============================] - 0s 60us/sample - loss: 0.4598 - accuracy: 0.9676\n",
      "Epoch 3/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.3214 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.2133 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.1431 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.0994 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.0730 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "432/432 [==============================] - 0s 58us/sample - loss: 0.0555 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.0437 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.0353 - accuracy: 1.0000\n",
      "432/432 [==============================] - 0s 127us/sample - loss: 0.0318 - accuracy: 1.0000\n",
      "120/120 [==============================] - 0s 384us/sample - loss: 0.0319 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "base_path = '../Data/resultVecs/resultVecs_5/'\n",
    "\n",
    "X_i = []\n",
    "y = []\n",
    "\n",
    "# auto_corr            hadamard           midAng\n",
    "\n",
    "for label in ['Bi', 'Tri']:\n",
    "    for feature in ['striping']:\n",
    "        for top, dir, f in os.walk(base_path + label + '/' + feature + '/'):\n",
    "            for filename in f:\n",
    "                data = open(os.path.join(base_path + label + '/' + feature + '/', filename), 'r')\n",
    "                data = data.read()\n",
    "                temp_data = []\n",
    "                for d in data.split():\n",
    "                    temp_data.append(float(d))\n",
    "                X_i.append(temp_data.copy())\n",
    "\n",
    "                if label == 'Bi':\n",
    "                    y.append(0)\n",
    "                else:\n",
    "                    y.append(1)\n",
    "\n",
    "print(len(X_i[0]))\n",
    "#print(y)\n",
    "\n",
    "X = np.array(X_i)\n",
    "y = np.array(y)\n",
    "\n",
    "an = []\n",
    "for i in range(10):\n",
    "    an.append(NN())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "final-telling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25309574879981855\n",
      "1.0\n",
      "0.2566891511281331\n",
      "0.9916667\n",
      "0.006981975933605874\n",
      "1.0\n",
      "0.00733046109477679\n",
      "1.0\n",
      "0.02605808050268226\n",
      "1.0\n",
      "0.026737013086676597\n",
      "1.0\n",
      "0.24363940236745057\n",
      "1.0\n",
      "0.24307318329811095\n",
      "1.0\n",
      "0.014855804853141308\n",
      "1.0\n",
      "0.01582947274049123\n",
      "1.0\n",
      "0.02165685342279849\n",
      "1.0\n",
      "0.0214355006814003\n",
      "1.0\n",
      "0.01752390250287674\n",
      "1.0\n",
      "0.019369543716311454\n",
      "1.0\n",
      "0.03832055642097085\n",
      "1.0\n",
      "0.03902919292449951\n",
      "1.0\n",
      "0.2641157827995442\n",
      "0.9861111\n",
      "0.2656690180301666\n",
      "0.98333335\n",
      "0.031821215939190656\n",
      "1.0\n",
      "0.03185646409789721\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for data in an:\n",
    "    for d in data:\n",
    "        for var in d:\n",
    "            print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "spare-longitude",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 432 samples\n",
      "Epoch 1/10\n",
      "432/432 [==============================] - 0s 324us/sample - loss: 0.4369 - accuracy: 0.9236\n",
      "Epoch 2/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.2500 - accuracy: 0.9907\n",
      "Epoch 3/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.1417 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.0847 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "432/432 [==============================] - 0s 60us/sample - loss: 0.0552 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "432/432 [==============================] - 0s 60us/sample - loss: 0.0382 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "432/432 [==============================] - 0s 67us/sample - loss: 0.0284 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.0220 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "432/432 [==============================] - 0s 60us/sample - loss: 0.0175 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "432/432 [==============================] - 0s 60us/sample - loss: 0.0142 - accuracy: 1.0000\n",
      "432/432 [==============================] - 0s 132us/sample - loss: 0.0128 - accuracy: 1.0000\n",
      "120/120 [==============================] - 0s 400us/sample - loss: 0.0137 - accuracy: 1.0000\n",
      "Train on 432 samples\n",
      "Epoch 1/10\n",
      "432/432 [==============================] - 0s 331us/sample - loss: 0.5127 - accuracy: 0.7315\n",
      "Epoch 2/10\n",
      "432/432 [==============================] - 0s 60us/sample - loss: 0.3388 - accuracy: 0.9699\n",
      "Epoch 3/10\n",
      "432/432 [==============================] - 0s 60us/sample - loss: 0.1893 - accuracy: 0.9977\n",
      "Epoch 4/10\n",
      "432/432 [==============================] - 0s 60us/sample - loss: 0.1036 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "432/432 [==============================] - 0s 60us/sample - loss: 0.0628 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.0419 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.0304 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "432/432 [==============================] - 0s 60us/sample - loss: 0.0234 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "432/432 [==============================] - 0s 60us/sample - loss: 0.0184 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "432/432 [==============================] - 0s 58us/sample - loss: 0.0151 - accuracy: 1.0000\n",
      "432/432 [==============================] - 0s 132us/sample - loss: 0.0135 - accuracy: 1.0000\n",
      "120/120 [==============================] - 0s 392us/sample - loss: 0.0147 - accuracy: 1.0000\n",
      "Train on 432 samples\n",
      "Epoch 1/10\n",
      "432/432 [==============================] - 0s 327us/sample - loss: 0.7593 - accuracy: 0.6088\n",
      "Epoch 2/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.4741 - accuracy: 0.9306\n",
      "Epoch 3/10\n",
      "432/432 [==============================] - 0s 58us/sample - loss: 0.3219 - accuracy: 0.9931\n",
      "Epoch 4/10\n",
      "432/432 [==============================] - 0s 60us/sample - loss: 0.2189 - accuracy: 0.9954\n",
      "Epoch 5/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.1491 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "432/432 [==============================] - 0s 60us/sample - loss: 0.1051 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.0767 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.0583 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.0455 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "432/432 [==============================] - 0s 60us/sample - loss: 0.0366 - accuracy: 1.0000\n",
      "432/432 [==============================] - 0s 132us/sample - loss: 0.0329 - accuracy: 1.0000\n",
      "120/120 [==============================] - 0s 409us/sample - loss: 0.0328 - accuracy: 1.0000\n",
      "Train on 432 samples\n",
      "Epoch 1/10\n",
      "432/432 [==============================] - 0s 331us/sample - loss: 0.6000 - accuracy: 0.7616\n",
      "Epoch 2/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.4344 - accuracy: 0.9884\n",
      "Epoch 3/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.2950 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "432/432 [==============================] - 0s 58us/sample - loss: 0.1975 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.1348 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.0963 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "432/432 [==============================] - 0s 60us/sample - loss: 0.0713 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "432/432 [==============================] - 0s 60us/sample - loss: 0.0551 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "432/432 [==============================] - 0s 60us/sample - loss: 0.0439 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "432/432 [==============================] - 0s 60us/sample - loss: 0.0357 - accuracy: 1.0000\n",
      "432/432 [==============================] - 0s 424us/sample - loss: 0.0322 - accuracy: 1.0000\n",
      "120/120 [==============================] - 0s 400us/sample - loss: 0.0335 - accuracy: 1.0000\n",
      "Train on 432 samples\n",
      "Epoch 1/10\n",
      "432/432 [==============================] - 0s 336us/sample - loss: 0.5381 - accuracy: 0.7407\n",
      "Epoch 2/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.2721 - accuracy: 0.9931\n",
      "Epoch 3/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.1581 - accuracy: 0.9977\n",
      "Epoch 4/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.1019 - accuracy: 0.9977\n",
      "Epoch 5/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.0705 - accuracy: 0.9977\n",
      "Epoch 6/10\n",
      "432/432 [==============================] - 0s 67us/sample - loss: 0.0508 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.0389 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "432/432 [==============================] - 0s 67us/sample - loss: 0.0305 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "432/432 [==============================] - 0s 79us/sample - loss: 0.0248 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "432/432 [==============================] - 0s 72us/sample - loss: 0.0206 - accuracy: 1.0000\n",
      "432/432 [==============================] - 0s 130us/sample - loss: 0.0185 - accuracy: 1.0000\n",
      "120/120 [==============================] - 0s 400us/sample - loss: 0.0191 - accuracy: 1.0000\n",
      "Train on 432 samples\n",
      "Epoch 1/10\n",
      "432/432 [==============================] - 0s 336us/sample - loss: 0.6687 - accuracy: 0.6042\n",
      "Epoch 2/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.4265 - accuracy: 0.9375\n",
      "Epoch 3/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.2231 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "432/432 [==============================] - 0s 67us/sample - loss: 0.1191 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.0716 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "432/432 [==============================] - 0s 67us/sample - loss: 0.0484 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.0350 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "432/432 [==============================] - 0s 70us/sample - loss: 0.0268 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "432/432 [==============================] - 0s 86us/sample - loss: 0.0214 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "432/432 [==============================] - 0s 72us/sample - loss: 0.0175 - accuracy: 1.0000\n",
      "432/432 [==============================] - 0s 139us/sample - loss: 0.0158 - accuracy: 1.0000\n",
      "120/120 [==============================] - 0s 425us/sample - loss: 0.0153 - accuracy: 1.0000\n",
      "Train on 432 samples\n",
      "Epoch 1/10\n",
      "432/432 [==============================] - 0s 341us/sample - loss: 0.4976 - accuracy: 0.7431\n",
      "Epoch 2/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.3963 - accuracy: 0.9352\n",
      "Epoch 3/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.3520 - accuracy: 0.9745\n",
      "Epoch 4/10\n",
      "432/432 [==============================] - 0s 70us/sample - loss: 0.3264 - accuracy: 0.9884\n",
      "Epoch 5/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.3066 - accuracy: 0.9931\n",
      "Epoch 6/10\n",
      "432/432 [==============================] - 0s 67us/sample - loss: 0.2903 - accuracy: 0.9954\n",
      "Epoch 7/10\n",
      "432/432 [==============================] - 0s 67us/sample - loss: 0.2774 - accuracy: 1.0000\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "432/432 [==============================] - 0s 70us/sample - loss: 0.2642 - accuracy: 0.9954\n",
      "Epoch 9/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.2524 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.2416 - accuracy: 1.0000\n",
      "432/432 [==============================] - 0s 134us/sample - loss: 0.2364 - accuracy: 1.0000\n",
      "120/120 [==============================] - 0s 400us/sample - loss: 0.2367 - accuracy: 1.0000\n",
      "Train on 432 samples\n",
      "Epoch 1/10\n",
      "432/432 [==============================] - 0s 339us/sample - loss: 0.5468 - accuracy: 0.7685\n",
      "Epoch 2/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.3330 - accuracy: 0.9861\n",
      "Epoch 3/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.2003 - accuracy: 0.9977\n",
      "Epoch 4/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.1218 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "432/432 [==============================] - 0s 67us/sample - loss: 0.0790 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.0550 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.0407 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "432/432 [==============================] - 0s 67us/sample - loss: 0.0312 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.0248 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.0203 - accuracy: 1.0000\n",
      "432/432 [==============================] - 0s 134us/sample - loss: 0.0183 - accuracy: 1.0000\n",
      "120/120 [==============================] - 0s 400us/sample - loss: 0.0190 - accuracy: 1.0000\n",
      "Train on 432 samples\n",
      "Epoch 1/10\n",
      "432/432 [==============================] - 0s 341us/sample - loss: 0.5763 - accuracy: 0.8102\n",
      "Epoch 2/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.4755 - accuracy: 0.9630\n",
      "Epoch 3/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.3543 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.2428 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.1615 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "432/432 [==============================] - 0s 70us/sample - loss: 0.1106 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.0797 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "432/432 [==============================] - 0s 60us/sample - loss: 0.0594 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.0460 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.0368 - accuracy: 1.0000\n",
      "432/432 [==============================] - 0s 134us/sample - loss: 0.0329 - accuracy: 1.0000\n",
      "120/120 [==============================] - 0s 396us/sample - loss: 0.0329 - accuracy: 1.0000\n",
      "Train on 432 samples\n",
      "Epoch 1/10\n",
      "432/432 [==============================] - 0s 338us/sample - loss: 0.5796 - accuracy: 0.6944\n",
      "Epoch 2/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.3460 - accuracy: 0.9815\n",
      "Epoch 3/10\n",
      "432/432 [==============================] - 0s 67us/sample - loss: 0.2180 - accuracy: 0.9954\n",
      "Epoch 4/10\n",
      "432/432 [==============================] - 0s 67us/sample - loss: 0.1377 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.0909 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "432/432 [==============================] - 0s 65us/sample - loss: 0.0638 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "432/432 [==============================] - 0s 67us/sample - loss: 0.0475 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "432/432 [==============================] - 0s 67us/sample - loss: 0.0370 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "432/432 [==============================] - 0s 67us/sample - loss: 0.0291 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "432/432 [==============================] - 0s 63us/sample - loss: 0.0237 - accuracy: 1.0000\n",
      "432/432 [==============================] - 0s 132us/sample - loss: 0.0214 - accuracy: 1.0000\n",
      "120/120 [==============================] - 0s 392us/sample - loss: 0.0216 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "X_i = []\n",
    "y = []\n",
    "\n",
    "for label in ['Bi', 'Tri']:\n",
    "    for feature in ['striping_midAng']:\n",
    "        for top, dir, f in os.walk(base_path + label + '/' + feature + '/'):\n",
    "            for filename in f:\n",
    "                data = open(os.path.join(base_path + label + '/' + feature + '/', filename), 'r')\n",
    "                data = data.read()\n",
    "                temp_data = []\n",
    "                for d in data.split():\n",
    "                    temp_data.append(float(d))\n",
    "                X_i.append(temp_data.copy())\n",
    "\n",
    "                if label == 'Bi':\n",
    "                    y.append(0)\n",
    "                else:\n",
    "                    y.append(1)\n",
    "                    \n",
    "X = np.array(X_i)\n",
    "y = np.array(y)\n",
    "\n",
    "an = []\n",
    "for i in range(10):\n",
    "    an.append(NN())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "mineral-hazard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012762359205495429\n",
      "1.0\n",
      "0.013683529198169708\n",
      "1.0\n",
      "0.013542647508007509\n",
      "1.0\n",
      "0.01467053492863973\n",
      "1.0\n",
      "0.03289835168807595\n",
      "1.0\n",
      "0.03277341797947884\n",
      "1.0\n",
      "0.032231683256449525\n",
      "1.0\n",
      "0.033481878538926445\n",
      "1.0\n",
      "0.018521131844156317\n",
      "1.0\n",
      "0.019129656006892523\n",
      "1.0\n",
      "0.015802074499704218\n",
      "1.0\n",
      "0.015338436452051003\n",
      "1.0\n",
      "0.2364409946733051\n",
      "1.0\n",
      "0.23668288191159567\n",
      "1.0\n",
      "0.018279168030454054\n",
      "1.0\n",
      "0.01900093083580335\n",
      "1.0\n",
      "0.03291322932475143\n",
      "1.0\n",
      "0.03289003732303778\n",
      "1.0\n",
      "0.021388248988875636\n",
      "1.0\n",
      "0.021586231887340546\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for data in an:\n",
    "    for d in data:\n",
    "        for var in d:\n",
    "            print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "american-rotation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nX_i = []\\ny = []\\n\\nfor label in ['Bi', 'Tri']:\\n    for feature in ['midAng']:\\n        for top, dir, f in os.walk(base_path + label + '/' + feature + '/'):\\n            for filename in f:\\n                data = open(os.path.join(base_path + label + '/' + feature + '/', filename), 'r')\\n                data = data.read()\\n                temp_data = []\\n                for d in data.split():\\n                    temp_data.append(float(d))\\n                X_i.append(temp_data.copy())\\n\\n                if label == 'Bi':\\n                    y.append(0)\\n                else:\\n                    y.append(1)\\n                    \\nX = np.array(X_i)\\ny = np.array(y)\\n\\nan = []\\nfor i in range(10):\\n    an.append(NN())\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "X_i = []\n",
    "y = []\n",
    "\n",
    "for label in ['Bi', 'Tri']:\n",
    "    for feature in ['midAng']:\n",
    "        for top, dir, f in os.walk(base_path + label + '/' + feature + '/'):\n",
    "            for filename in f:\n",
    "                data = open(os.path.join(base_path + label + '/' + feature + '/', filename), 'r')\n",
    "                data = data.read()\n",
    "                temp_data = []\n",
    "                for d in data.split():\n",
    "                    temp_data.append(float(d))\n",
    "                X_i.append(temp_data.copy())\n",
    "\n",
    "                if label == 'Bi':\n",
    "                    y.append(0)\n",
    "                else:\n",
    "                    y.append(1)\n",
    "                    \n",
    "X = np.array(X_i)\n",
    "y = np.array(y)\n",
    "\n",
    "an = []\n",
    "for i in range(10):\n",
    "    an.append(NN())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "automotive-surveillance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor data in an:\\n    for d in data:\\n        for var in d:\\n            print(var)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for data in an:\n",
    "    for d in data:\n",
    "        for var in d:\n",
    "            print(var)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

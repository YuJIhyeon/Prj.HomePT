{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "incorporate-workshop",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "talented-messaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "session = tf.compat.v1.InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "elder-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '../Data/resultVecs/resultVecs_20/'\n",
    "\n",
    "X_i = []\n",
    "y = []\n",
    "\n",
    "for label in ['Bi', 'Tri']:\n",
    "    for feature in ['striping']:\n",
    "        for top, dir, f in os.walk(base_path + label + '/' + feature + '/'):\n",
    "            for filename in f:\n",
    "                data = open(os.path.join(base_path + label + '/' + feature + '/', filename), 'r')\n",
    "                data = data.read()\n",
    "                temp_data = []\n",
    "                for d in data.split():\n",
    "                    temp_data.append(float(d))\n",
    "                X_i.append(temp_data.copy())\n",
    "\n",
    "                if label == 'Bi':\n",
    "                    y.append(0)\n",
    "                else:\n",
    "                    y.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unknown-receipt",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n"
     ]
    }
   ],
   "source": [
    "print(len(X_i[0]))\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "floral-bowling",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X_i)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "homeless-spouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def NN():\n",
    "    \n",
    "    evaluation = []\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    # validation split\n",
    "\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.1, random_state=10, stratify=y_train)\n",
    "    Neural_Network = keras.models.Sequential([\n",
    "    # input layer\n",
    "    keras.layers.Dense(256, activation='relu', input_shape=(144,)),\n",
    "\n",
    "    # hidden layer 1\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "\n",
    "    # hidden layer 2\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "\n",
    "    # output layer\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "    ])\n",
    "    #Neural_Network.summary()\n",
    "    Neural_Network.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    Neural_Network.fit(X_train, y_train, epochs=10, batch_size=16, verbose=1)\n",
    "    evaluation.append(Neural_Network.evaluate(X_train, y_train, batch_size=16))\n",
    "    evaluation.append(Neural_Network.evaluate(X_test, y_test, batch_size=16))\n",
    "    return evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "tired-baltimore",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1728 samples\n",
      "Epoch 1/10\n",
      "1728/1728 [==============================] - 1s 291us/sample - loss: 0.0268 - accuracy: 0.9884\n",
      "Epoch 2/10\n",
      "1728/1728 [==============================] - 0s 84us/sample - loss: 4.6322e-05 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "1728/1728 [==============================] - 0s 73us/sample - loss: 2.5758e-05 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1728/1728 [==============================] - 0s 80us/sample - loss: 2.2841e-05 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1728/1728 [==============================] - 0s 75us/sample - loss: 4.4992e-06 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1728/1728 [==============================] - 0s 72us/sample - loss: 3.8052e-06 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1728/1728 [==============================] - 0s 72us/sample - loss: 6.3287e-06 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1728/1728 [==============================] - 0s 82us/sample - loss: 1.8785e-06 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1728/1728 [==============================] - 0s 75us/sample - loss: 1.4605e-06 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1728/1728 [==============================] - 0s 71us/sample - loss: 1.2009e-06 - accuracy: 1.0000\n",
      "1728/1728 [==============================] - 0s 75us/sample - loss: 8.7576e-07 - accuracy: 1.0000\n",
      "480/480 [==============================] - 0s 56us/sample - loss: 6.1069e-07 - accuracy: 1.0000\n",
      "Train on 1728 samples\n",
      "Epoch 1/10\n",
      "1728/1728 [==============================] - 0s 164us/sample - loss: 0.0268 - accuracy: 0.9884\n",
      "Epoch 2/10\n",
      "1728/1728 [==============================] - 0s 73us/sample - loss: 1.1821e-05 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "1728/1728 [==============================] - 0s 78us/sample - loss: 4.1717e-06 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1728/1728 [==============================] - 0s 76us/sample - loss: 1.4636e-06 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1728/1728 [==============================] - 0s 77us/sample - loss: 8.9106e-07 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1728/1728 [==============================] - 0s 78us/sample - loss: 5.7561e-07 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1728/1728 [==============================] - 0s 76us/sample - loss: 3.8446e-07 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1728/1728 [==============================] - 0s 77us/sample - loss: 2.5263e-07 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1728/1728 [==============================] - 0s 76us/sample - loss: 1.8309e-07 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1728/1728 [==============================] - 0s 74us/sample - loss: 1.3307e-07 - accuracy: 1.0000\n",
      "1728/1728 [==============================] - 0s 76us/sample - loss: 1.1238e-07 - accuracy: 1.0000\n",
      "480/480 [==============================] - 0s 60us/sample - loss: 1.5596e-07 - accuracy: 1.0000\n",
      "Train on 1728 samples\n",
      "Epoch 1/10\n",
      "1728/1728 [==============================] - 0s 160us/sample - loss: 0.0231 - accuracy: 0.9954\n",
      "Epoch 2/10\n",
      "1728/1728 [==============================] - 0s 73us/sample - loss: 7.6634e-06 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "1728/1728 [==============================] - 0s 74us/sample - loss: 4.9857e-06 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1728/1728 [==============================] - 0s 74us/sample - loss: 2.0565e-06 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1728/1728 [==============================] - 0s 82us/sample - loss: 9.8502e-07 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1728/1728 [==============================] - 0s 77us/sample - loss: 5.8623e-07 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1728/1728 [==============================] - 0s 78us/sample - loss: 3.8501e-07 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1728/1728 [==============================] - 0s 74us/sample - loss: 2.6111e-07 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1728/1728 [==============================] - 0s 74us/sample - loss: 1.9013e-07 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1728/1728 [==============================] - 0s 77us/sample - loss: 1.5343e-07 - accuracy: 1.0000\n",
      "1728/1728 [==============================] - 0s 81us/sample - loss: 1.1438e-07 - accuracy: 1.0000\n",
      "480/480 [==============================] - 0s 58us/sample - loss: 2.3444e-07 - accuracy: 1.0000\n",
      "Train on 1728 samples\n",
      "Epoch 1/10\n",
      "1728/1728 [==============================] - 0s 160us/sample - loss: 0.0214 - accuracy: 0.9942\n",
      "Epoch 2/10\n",
      "1728/1728 [==============================] - 0s 72us/sample - loss: 1.8414e-05 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "1728/1728 [==============================] - 0s 71us/sample - loss: 1.1571e-05 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1728/1728 [==============================] - 0s 74us/sample - loss: 7.8114e-06 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1728/1728 [==============================] - 0s 75us/sample - loss: 6.8334e-06 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1728/1728 [==============================] - 0s 86us/sample - loss: 6.5084e-06 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1728/1728 [==============================] - 0s 88us/sample - loss: 3.0173e-06 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1728/1728 [==============================] - 0s 82us/sample - loss: 2.8988e-06 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1728/1728 [==============================] - 0s 80us/sample - loss: 2.0963e-06 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1728/1728 [==============================] - 0s 82us/sample - loss: 1.8258e-06 - accuracy: 1.0000\n",
      "1728/1728 [==============================] - 0s 89us/sample - loss: 1.3721e-06 - accuracy: 1.0000\n",
      "480/480 [==============================] - 0s 67us/sample - loss: 1.5422e-06 - accuracy: 1.0000\n",
      "Train on 1728 samples\n",
      "Epoch 1/10\n",
      "1728/1728 [==============================] - 0s 165us/sample - loss: 0.0281 - accuracy: 0.9931\n",
      "Epoch 2/10\n",
      "1728/1728 [==============================] - 0s 73us/sample - loss: 1.5226e-05 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "1728/1728 [==============================] - 0s 74us/sample - loss: 6.1718e-06 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1728/1728 [==============================] - 0s 74us/sample - loss: 3.0711e-06 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1728/1728 [==============================] - 0s 72us/sample - loss: 1.4922e-06 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1728/1728 [==============================] - 0s 72us/sample - loss: 9.5184e-07 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1728/1728 [==============================] - 0s 72us/sample - loss: 6.9384e-07 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1728/1728 [==============================] - 0s 73us/sample - loss: 5.0359e-07 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1728/1728 [==============================] - 0s 72us/sample - loss: 3.7694e-07 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1728/1728 [==============================] - 0s 73us/sample - loss: 2.8050e-07 - accuracy: 1.0000\n",
      "1728/1728 [==============================] - 0s 77us/sample - loss: 2.4531e-07 - accuracy: 1.0000\n",
      "480/480 [==============================] - 0s 56us/sample - loss: 5.5083e-07 - accuracy: 1.0000\n",
      "Train on 1728 samples\n",
      "Epoch 1/10\n",
      "1728/1728 [==============================] - 0s 219us/sample - loss: 0.0191 - accuracy: 0.9965\n",
      "Epoch 2/10\n",
      "1728/1728 [==============================] - 0s 71us/sample - loss: 1.0588e-05 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "1728/1728 [==============================] - 0s 71us/sample - loss: 2.9363e-06 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1728/1728 [==============================] - 0s 72us/sample - loss: 1.5460e-06 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1728/1728 [==============================] - 0s 71us/sample - loss: 7.1068e-07 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1728/1728 [==============================] - 0s 72us/sample - loss: 4.4627e-07 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1728/1728 [==============================] - 0s 72us/sample - loss: 2.6042e-07 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1728/1728 [==============================] - 0s 72us/sample - loss: 2.0089e-07 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1728/1728 [==============================] - 0s 71us/sample - loss: 1.3970e-07 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1728/1728 [==============================] - 0s 72us/sample - loss: 1.0983e-07 - accuracy: 1.0000\n",
      "1728/1728 [==============================] - 0s 79us/sample - loss: 9.3270e-08 - accuracy: 1.0000\n",
      "480/480 [==============================] - 0s 63us/sample - loss: 2.8187e-07 - accuracy: 1.0000\n",
      "Train on 1728 samples\n",
      "Epoch 1/10\n",
      "1728/1728 [==============================] - 0s 159us/sample - loss: 0.0356 - accuracy: 0.9861\n",
      "Epoch 2/10\n",
      "1728/1728 [==============================] - 0s 72us/sample - loss: 2.4774e-05 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "1728/1728 [==============================] - 0s 72us/sample - loss: 9.8644e-06 - accuracy: 1.0000\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728/1728 [==============================] - 0s 72us/sample - loss: 5.2883e-06 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1728/1728 [==============================] - 0s 71us/sample - loss: 3.8524e-06 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1728/1728 [==============================] - 0s 70us/sample - loss: 2.9965e-06 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1728/1728 [==============================] - 0s 71us/sample - loss: 1.3824e-06 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1728/1728 [==============================] - 0s 72us/sample - loss: 9.5656e-07 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1728/1728 [==============================] - 0s 72us/sample - loss: 6.0774e-07 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1728/1728 [==============================] - 0s 72us/sample - loss: 4.2991e-07 - accuracy: 1.0000\n",
      "1728/1728 [==============================] - 0s 76us/sample - loss: 3.7369e-07 - accuracy: 1.0000\n",
      "480/480 [==============================] - 0s 56us/sample - loss: 7.8226e-07 - accuracy: 1.0000\n",
      "Train on 1728 samples\n",
      "Epoch 1/10\n",
      "1728/1728 [==============================] - 0s 160us/sample - loss: 0.0167 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "1728/1728 [==============================] - 0s 72us/sample - loss: 7.8930e-06 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "1728/1728 [==============================] - 0s 73us/sample - loss: 5.8042e-06 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1728/1728 [==============================] - 0s 72us/sample - loss: 4.2072e-06 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1728/1728 [==============================] - 0s 74us/sample - loss: 1.9516e-06 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1728/1728 [==============================] - 0s 73us/sample - loss: 1.4609e-06 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1728/1728 [==============================] - 0s 74us/sample - loss: 1.0454e-06 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1728/1728 [==============================] - 0s 74us/sample - loss: 7.9180e-07 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1728/1728 [==============================] - 0s 74us/sample - loss: 5.6830e-07 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1728/1728 [==============================] - 0s 73us/sample - loss: 4.6689e-07 - accuracy: 1.0000\n",
      "1728/1728 [==============================] - 0s 77us/sample - loss: 3.6362e-07 - accuracy: 1.0000\n",
      "480/480 [==============================] - 0s 58us/sample - loss: 4.5721e-07 - accuracy: 1.0000\n",
      "Train on 1728 samples\n",
      "Epoch 1/10\n",
      "1728/1728 [==============================] - 0s 159us/sample - loss: 0.0227 - accuracy: 0.9954\n",
      "Epoch 2/10\n",
      "1728/1728 [==============================] - 0s 75us/sample - loss: 1.3632e-05 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "1728/1728 [==============================] - 0s 73us/sample - loss: 1.0627e-05 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1728/1728 [==============================] - 0s 74us/sample - loss: 7.2393e-06 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1728/1728 [==============================] - 0s 75us/sample - loss: 3.6704e-06 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1728/1728 [==============================] - 0s 75us/sample - loss: 2.6172e-06 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1728/1728 [==============================] - 0s 76us/sample - loss: 2.0800e-06 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1728/1728 [==============================] - 0s 75us/sample - loss: 1.3402e-06 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1728/1728 [==============================] - 0s 74us/sample - loss: 1.0634e-06 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1728/1728 [==============================] - 0s 75us/sample - loss: 7.7103e-07 - accuracy: 1.0000\n",
      "1728/1728 [==============================] - 0s 76us/sample - loss: 6.5667e-07 - accuracy: 1.0000\n",
      "480/480 [==============================] - 0s 56us/sample - loss: 2.1226e-06 - accuracy: 1.0000\n",
      "Train on 1728 samples\n",
      "Epoch 1/10\n",
      "1728/1728 [==============================] - 0s 160us/sample - loss: 0.0281 - accuracy: 0.9948\n",
      "Epoch 2/10\n",
      "1728/1728 [==============================] - 0s 72us/sample - loss: 3.9394e-05 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "1728/1728 [==============================] - 0s 73us/sample - loss: 5.8589e-06 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1728/1728 [==============================] - 0s 74us/sample - loss: 3.0405e-06 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1728/1728 [==============================] - 0s 75us/sample - loss: 2.3513e-06 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1728/1728 [==============================] - 0s 74us/sample - loss: 2.2712e-06 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1728/1728 [==============================] - 0s 74us/sample - loss: 2.2542e-06 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1728/1728 [==============================] - 0s 73us/sample - loss: 8.7446e-07 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1728/1728 [==============================] - 0s 72us/sample - loss: 7.0058e-07 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1728/1728 [==============================] - 0s 72us/sample - loss: 5.4566e-07 - accuracy: 1.0000\n",
      "1728/1728 [==============================] - 0s 76us/sample - loss: 4.5757e-07 - accuracy: 1.0000\n",
      "480/480 [==============================] - 0s 56us/sample - loss: 7.8649e-07 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "an = []\n",
    "for i in range(10):\n",
    "    an.append(NN())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "spare-longitude",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.757592872040739e-07\n",
      "1.0\n",
      "6.106866971222757e-07\n",
      "1.0\n",
      "1.1237900380637693e-07\n",
      "1.0\n",
      "1.5596447542343128e-07\n",
      "1.0\n",
      "1.1437957661666989e-07\n",
      "1.0\n",
      "2.3444166277937957e-07\n",
      "1.0\n",
      "1.3720588019483916e-06\n",
      "1.0\n",
      "1.5421724987400391e-06\n",
      "1.0\n",
      "2.453139959727961e-07\n",
      "1.0\n",
      "5.508283674663754e-07\n",
      "1.0\n",
      "9.326998406533204e-08\n",
      "1.0\n",
      "2.818746021778414e-07\n",
      "1.0\n",
      "3.736920073094941e-07\n",
      "1.0\n",
      "7.822583704353292e-07\n",
      "1.0\n",
      "3.636229257985301e-07\n",
      "1.0\n",
      "4.5721067881328755e-07\n",
      "1.0\n",
      "6.56673095488924e-07\n",
      "1.0\n",
      "2.1226484856621636e-06\n",
      "1.0\n",
      "4.5757039581597436e-07\n",
      "1.0\n",
      "7.86488941795227e-07\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for data in an:\n",
    "    for d in data:\n",
    "        for var in d:\n",
    "            print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "athletic-stage",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_i = []\n",
    "y = []\n",
    "\n",
    "for label in ['Bi', 'Tri']:\n",
    "    for feature in ['striping_midAng']:\n",
    "        for top, dir, f in os.walk(base_path + label + '/' + feature + '/'):\n",
    "            for filename in f:\n",
    "                data = open(os.path.join(base_path + label + '/' + feature + '/', filename), 'r')\n",
    "                data = data.read()\n",
    "                temp_data = []\n",
    "                for d in data.split():\n",
    "                    temp_data.append(float(d))\n",
    "                X_i.append(temp_data.copy())\n",
    "\n",
    "                if label == 'Bi':\n",
    "                    y.append(0)\n",
    "                else:\n",
    "                    y.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "imported-andorra",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1728 samples\n",
      "Epoch 1/10\n",
      "1728/1728 [==============================] - 0s 163us/sample - loss: 0.0300 - accuracy: 0.9942\n",
      "Epoch 2/10\n",
      "1728/1728 [==============================] - 0s 75us/sample - loss: 1.6834e-05 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "1728/1728 [==============================] - 0s 75us/sample - loss: 7.8177e-06 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1728/1728 [==============================] - 0s 75us/sample - loss: 3.6087e-06 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1728/1728 [==============================] - 0s 79us/sample - loss: 1.3518e-06 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1728/1728 [==============================] - 0s 76us/sample - loss: 7.3110e-07 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1728/1728 [==============================] - 0s 76us/sample - loss: 4.8573e-07 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1728/1728 [==============================] - 0s 77us/sample - loss: 3.1568e-07 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1728/1728 [==============================] - 0s 78us/sample - loss: 2.3421e-07 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1728/1728 [==============================] - 0s 79us/sample - loss: 1.9061e-07 - accuracy: 1.0000\n",
      "1728/1728 [==============================] - 0s 79us/sample - loss: 1.5122e-07 - accuracy: 1.0000\n",
      "480/480 [==============================] - 0s 69us/sample - loss: 4.2690e-07 - accuracy: 1.0000\n",
      "Train on 1728 samples\n",
      "Epoch 1/10\n",
      "1728/1728 [==============================] - 0s 163us/sample - loss: 0.0235 - accuracy: 0.9925\n",
      "Epoch 2/10\n",
      "1728/1728 [==============================] - 0s 75us/sample - loss: 2.6550e-05 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "1728/1728 [==============================] - 0s 83us/sample - loss: 9.9487e-06 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1728/1728 [==============================] - 0s 76us/sample - loss: 5.1584e-06 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1728/1728 [==============================] - 0s 75us/sample - loss: 2.8596e-06 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1728/1728 [==============================] - 0s 79us/sample - loss: 1.9623e-06 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1728/1728 [==============================] - 0s 80us/sample - loss: 1.3242e-06 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1728/1728 [==============================] - 0s 75us/sample - loss: 1.0072e-06 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1728/1728 [==============================] - 0s 76us/sample - loss: 7.3758e-07 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1728/1728 [==============================] - 0s 77us/sample - loss: 5.7237e-07 - accuracy: 1.0000\n",
      "1728/1728 [==============================] - 0s 81us/sample - loss: 4.9056e-07 - accuracy: 1.0000\n",
      "480/480 [==============================] - 0s 58us/sample - loss: 9.0769e-07 - accuracy: 1.0000\n",
      "Train on 1728 samples\n",
      "Epoch 1/10\n",
      "1728/1728 [==============================] - 0s 165us/sample - loss: 0.0271 - accuracy: 0.9925\n",
      "Epoch 2/10\n",
      "1728/1728 [==============================] - 0s 73us/sample - loss: 1.8432e-05 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "1728/1728 [==============================] - 0s 74us/sample - loss: 8.1000e-06 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1728/1728 [==============================] - 0s 76us/sample - loss: 4.4070e-06 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1728/1728 [==============================] - 0s 79us/sample - loss: 3.6489e-06 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1728/1728 [==============================] - 0s 74us/sample - loss: 2.6854e-06 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1728/1728 [==============================] - 0s 75us/sample - loss: 1.3544e-06 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1728/1728 [==============================] - 0s 72us/sample - loss: 1.2415e-06 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1728/1728 [==============================] - 0s 72us/sample - loss: 8.2443e-07 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1728/1728 [==============================] - 0s 71us/sample - loss: 4.0494e-07 - accuracy: 1.0000\n",
      "1728/1728 [==============================] - 0s 76us/sample - loss: 3.4706e-07 - accuracy: 1.0000\n",
      "480/480 [==============================] - 0s 56us/sample - loss: 1.3804e-06 - accuracy: 1.0000\n",
      "Train on 1728 samples\n",
      "Epoch 1/10\n",
      "1728/1728 [==============================] - 0s 161us/sample - loss: 0.0182 - accuracy: 0.9954\n",
      "Epoch 2/10\n",
      "1728/1728 [==============================] - 0s 72us/sample - loss: 7.8432e-06 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "1728/1728 [==============================] - 0s 74us/sample - loss: 5.2816e-06 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1728/1728 [==============================] - 0s 74us/sample - loss: 2.7285e-06 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1728/1728 [==============================] - 0s 73us/sample - loss: 1.6693e-06 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1728/1728 [==============================] - 0s 73us/sample - loss: 1.3740e-06 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1728/1728 [==============================] - 0s 72us/sample - loss: 8.1938e-07 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1728/1728 [==============================] - 0s 72us/sample - loss: 6.2768e-07 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1728/1728 [==============================] - 0s 72us/sample - loss: 4.4978e-07 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1728/1728 [==============================] - 0s 71us/sample - loss: 3.4596e-07 - accuracy: 1.0000\n",
      "1728/1728 [==============================] - 0s 76us/sample - loss: 2.7008e-07 - accuracy: 1.0000\n",
      "480/480 [==============================] - 0s 56us/sample - loss: 7.4624e-07 - accuracy: 1.0000\n",
      "Train on 1728 samples\n",
      "Epoch 1/10\n",
      "1728/1728 [==============================] - 0s 160us/sample - loss: 0.0265 - accuracy: 0.9936\n",
      "Epoch 2/10\n",
      "1728/1728 [==============================] - 0s 73us/sample - loss: 2.7935e-05 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "1728/1728 [==============================] - 0s 78us/sample - loss: 6.3386e-06 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1728/1728 [==============================] - 0s 78us/sample - loss: 4.0605e-06 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1728/1728 [==============================] - 0s 78us/sample - loss: 2.1295e-06 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1728/1728 [==============================] - 0s 74us/sample - loss: 1.7763e-06 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1728/1728 [==============================] - 0s 73us/sample - loss: 9.4574e-07 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1728/1728 [==============================] - 0s 74us/sample - loss: 7.3716e-07 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1728/1728 [==============================] - 0s 71us/sample - loss: 5.6615e-07 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1728/1728 [==============================] - 0s 72us/sample - loss: 4.3053e-07 - accuracy: 1.0000\n",
      "1728/1728 [==============================] - 0s 76us/sample - loss: 3.5120e-07 - accuracy: 1.0000\n",
      "480/480 [==============================] - 0s 54us/sample - loss: 3.9115e-07 - accuracy: 1.0000\n",
      "Train on 1728 samples\n",
      "Epoch 1/10\n",
      "1728/1728 [==============================] - 0s 159us/sample - loss: 0.0286 - accuracy: 0.9907\n",
      "Epoch 2/10\n",
      "1728/1728 [==============================] - 0s 72us/sample - loss: 1.4343e-05 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "1728/1728 [==============================] - 0s 73us/sample - loss: 5.8056e-06 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1728/1728 [==============================] - 0s 73us/sample - loss: 2.9005e-06 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1728/1728 [==============================] - 0s 72us/sample - loss: 1.6350e-06 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1728/1728 [==============================] - 0s 72us/sample - loss: 1.2490e-06 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1728/1728 [==============================] - 0s 72us/sample - loss: 1.1050e-06 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1728/1728 [==============================] - 0s 71us/sample - loss: 5.4622e-07 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1728/1728 [==============================] - 0s 75us/sample - loss: 4.2771e-07 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1728/1728 [==============================] - 0s 79us/sample - loss: 3.4900e-07 - accuracy: 1.0000\n",
      "1728/1728 [==============================] - 0s 78us/sample - loss: 2.8684e-07 - accuracy: 1.0000\n",
      "480/480 [==============================] - 0s 56us/sample - loss: 7.4649e-07 - accuracy: 1.0000\n",
      "Train on 1728 samples\n",
      "Epoch 1/10\n",
      "1728/1728 [==============================] - 0s 167us/sample - loss: 0.0265 - accuracy: 0.9873\n",
      "Epoch 2/10\n",
      "1728/1728 [==============================] - 0s 80us/sample - loss: 3.9012e-05 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "1728/1728 [==============================] - 0s 77us/sample - loss: 1.5762e-05 - accuracy: 1.0000\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1728/1728 [==============================] - 0s 79us/sample - loss: 7.1072e-06 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1728/1728 [==============================] - 0s 78us/sample - loss: 3.5046e-06 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1728/1728 [==============================] - 0s 78us/sample - loss: 1.7730e-06 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1728/1728 [==============================] - 0s 79us/sample - loss: 1.3554e-06 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1728/1728 [==============================] - 0s 76us/sample - loss: 7.4565e-07 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1728/1728 [==============================] - 0s 79us/sample - loss: 5.5347e-07 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1728/1728 [==============================] - 0s 78us/sample - loss: 4.0425e-07 - accuracy: 1.0000\n",
      "1728/1728 [==============================] - 0s 79us/sample - loss: 3.6300e-07 - accuracy: 1.0000\n",
      "480/480 [==============================] - 0s 60us/sample - loss: 5.4165e-07 - accuracy: 1.0000\n",
      "Train on 1728 samples\n",
      "Epoch 1/10\n",
      "1728/1728 [==============================] - 0s 163us/sample - loss: 0.0235 - accuracy: 0.9919\n",
      "Epoch 2/10\n",
      "1728/1728 [==============================] - 0s 75us/sample - loss: 1.2845e-05 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "1728/1728 [==============================] - 0s 73us/sample - loss: 5.7784e-06 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1728/1728 [==============================] - 0s 75us/sample - loss: 3.1549e-06 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1728/1728 [==============================] - 0s 74us/sample - loss: 1.6355e-06 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1728/1728 [==============================] - 0s 74us/sample - loss: 1.1991e-06 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1728/1728 [==============================] - 0s 74us/sample - loss: 8.3862e-07 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1728/1728 [==============================] - 0s 76us/sample - loss: 6.2541e-07 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1728/1728 [==============================] - 0s 74us/sample - loss: 4.3909e-07 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1728/1728 [==============================] - 0s 73us/sample - loss: 3.6555e-07 - accuracy: 1.0000\n",
      "1728/1728 [==============================] - 0s 79us/sample - loss: 3.0781e-07 - accuracy: 1.0000\n",
      "480/480 [==============================] - 0s 58us/sample - loss: 9.6849e-07 - accuracy: 1.0000\n",
      "Train on 1728 samples\n",
      "Epoch 1/10\n",
      "1728/1728 [==============================] - 0s 171us/sample - loss: 0.0259 - accuracy: 0.9954\n",
      "Epoch 2/10\n",
      "1728/1728 [==============================] - 0s 78us/sample - loss: 2.3531e-05 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "1728/1728 [==============================] - 0s 79us/sample - loss: 7.8182e-06 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1728/1728 [==============================] - 0s 79us/sample - loss: 4.5873e-06 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1728/1728 [==============================] - 0s 76us/sample - loss: 1.9935e-06 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1728/1728 [==============================] - 0s 78us/sample - loss: 1.6499e-06 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1728/1728 [==============================] - 0s 78us/sample - loss: 8.2545e-07 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1728/1728 [==============================] - 0s 79us/sample - loss: 5.2835e-07 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1728/1728 [==============================] - 0s 77us/sample - loss: 4.0860e-07 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1728/1728 [==============================] - 0s 76us/sample - loss: 3.0492e-07 - accuracy: 1.0000\n",
      "1728/1728 [==============================] - 0s 79us/sample - loss: 2.6070e-07 - accuracy: 1.0000\n",
      "480/480 [==============================] - 0s 58us/sample - loss: 4.6367e-07 - accuracy: 1.0000\n",
      "Train on 1728 samples\n",
      "Epoch 1/10\n",
      "1728/1728 [==============================] - 0s 165us/sample - loss: 0.0473 - accuracy: 0.9855\n",
      "Epoch 2/10\n",
      "1728/1728 [==============================] - 0s 75us/sample - loss: 6.3968e-05 - accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "1728/1728 [==============================] - 0s 75us/sample - loss: 2.0205e-06 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1728/1728 [==============================] - 0s 76us/sample - loss: 9.5693e-07 - accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1728/1728 [==============================] - 0s 76us/sample - loss: 5.3491e-07 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1728/1728 [==============================] - 0s 74us/sample - loss: 3.5720e-07 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1728/1728 [==============================] - 0s 75us/sample - loss: 2.4593e-07 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1728/1728 [==============================] - 0s 72us/sample - loss: 1.8095e-07 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1728/1728 [==============================] - 0s 74us/sample - loss: 1.3811e-07 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1728/1728 [==============================] - 0s 74us/sample - loss: 1.0734e-07 - accuracy: 1.0000\n",
      "1728/1728 [==============================] - 0s 78us/sample - loss: 9.1407e-08 - accuracy: 1.0000\n",
      "480/480 [==============================] - 0s 60us/sample - loss: 2.8833e-07 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X_i)\n",
    "y = np.array(y)\n",
    "\n",
    "an = []\n",
    "for i in range(10):\n",
    "    an.append(NN())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "mineral-hazard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5121815451675977e-07\n",
      "1.0\n",
      "4.2690289535999664e-07\n",
      "1.0\n",
      "4.905569810365051e-07\n",
      "1.0\n",
      "9.076873993466942e-07\n",
      "1.0\n",
      "3.4706211659306937e-07\n",
      "1.0\n",
      "1.3803904313676914e-06\n",
      "1.0\n",
      "2.7007740292743447e-07\n",
      "1.0\n",
      "7.462410707000563e-07\n",
      "1.0\n",
      "3.5120010432742744e-07\n",
      "1.0\n",
      "3.9114831212512987e-07\n",
      "1.0\n",
      "2.868417868085305e-07\n",
      "1.0\n",
      "7.464925497598548e-07\n",
      "1.0\n",
      "3.630040143126828e-07\n",
      "1.0\n",
      "5.416476948738592e-07\n",
      "1.0\n",
      "3.078137572280708e-07\n",
      "1.0\n",
      "9.684937138339697e-07\n",
      "1.0\n",
      "2.606976034553238e-07\n",
      "1.0\n",
      "4.636663995564542e-07\n",
      "1.0\n",
      "9.140694244723511e-08\n",
      "1.0\n",
      "2.88327762894743e-07\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for data in an:\n",
    "    for d in data:\n",
    "        for var in d:\n",
    "            print(var)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
